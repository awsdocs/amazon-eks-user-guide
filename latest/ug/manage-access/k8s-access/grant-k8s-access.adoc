//!!NODE_ROOT <section>


[.topic]
[[grant-k8s-access,grant-k8s-access.title]]
= Grant [.noloc]`IAM` users and roles access to Kubernetes [.noloc]`APIs`
:info_doctype: section
:info_title: Grant IAM users and roles access to Kubernetes APIs
:info_titleabbrev: Grant access to Kubernetes APIs
:info_abstract: Learn how to grant access to Kubernetes APIs on Amazon EKS clusters using IAM roles, users, or OpenID Connect providers, and manage permissions with access entries or the aws-auth ConfigMap.

include::../../attributes.txt[]

[abstract]
--
Learn how to grant access to Kubernetes APIs on Amazon EKS clusters using IAM roles, users, or OpenID Connect providers, and manage permissions with access entries or the aws-auth ConfigMap.
--

Your cluster has an [.noloc]`Kubernetes` API endpoint. Kubectl uses this API. You can authenticate to this API using two types of identities:  



* *An {aws} Identity and Access Management (IAM) _principal_ (role or user)*
 – This type requires authentication to IAM. Users can sign in to {aws} as an link:IAM/latest/UserGuide/introduction.html[IAM,type="documentation"] user or with a link:identity/federation/[federated identity,type="marketing"] by using credentials provided through an identity source. Users can only sign in with a federated identity if your administrator previously set up identity federation using IAM roles. When users access {aws} by using federation, they're indirectly  link:IAM/latest/UserGuide/when-to-use-iam.html#security-iam-authentication-iamrole[assuming a role,type="documentation"]. When users use this type of identity, you:
+
** Can assign them [.noloc]`Kubernetes` permissions so that they can work with [.noloc]`Kubernetes` objects on your cluster. For more information about how to assign permissions to your IAM principals so that they're able to access [.noloc]`Kubernetes` objects on your cluster, see <<access-entries>>.
** Can assign them IAM permissions so that they can work with your Amazon EKS cluster and its resources using the Amazon EKS API, {aws} CLI, {aws} CloudFormation, {aws-management-console}, or `eksctl`. For more information, see  link:service-authorization/latest/reference/list_amazonelastickubernetesservice.html#amazonelastickubernetesservice-actions-as-permissions[Actions defined by Amazon Elastic Kubernetes Service,type="documentation"] in the Service Authorization Reference.
** Nodes join your cluster by assuming an IAM role. The ability to access your cluster using IAM principals is provided by the https://github.com/kubernetes-sigs/aws-iam-authenticator#readme[{aws} IAM Authenticator for Kubernetes], which runs on the Amazon EKS control plane. 
* *A user in your own [.noloc]`OpenID Connect` ([.noloc]`OIDC`) provider*
 – This type requires authentication to your https://openid.net/connect/[OIDC] provider. For more information about setting up your own [.noloc]`OIDC` provider with your Amazon EKS cluster, see <<authenticate-oidc-identity-provider>>. When users use this type of identity, you:
+
** Can assign them [.noloc]`Kubernetes` permissions so that they can work with [.noloc]`Kubernetes` objects on your cluster.
** Can't assign them IAM permissions so that they can work with your Amazon EKS cluster and its resources using the Amazon EKS API, {aws} CLI, {aws} CloudFormation, {aws-management-console}, or `eksctl`.

You can use both types of identities with your cluster. The IAM authentication method cannot be disabled. The OIDC authentication method is optional.

[[authentication-modes,authentication-modes.title]]
== Associate IAM Identities with Kubernetes Permissions

The https://github.com/kubernetes-sigs/aws-iam-authenticator#readme[{aws} IAM Authenticator for Kubernetes] is installed on your cluster's control plane. It enables link:IAM/latest/UserGuide/introduction.html[{aws} Identity and Access Management,type="documentation"] (IAM) principals (roles and users) that you allow to access [.noloc]`Kubernetes` resources on your cluster. You can allow IAM principals to access [.noloc]`Kubernetes` objects on your cluster using one of the following methods:



* *Creating access entries*
 – If your cluster is at or later than the platform version listed in the  <<access-entries,Prerequisites>> section for your cluster's [.noloc]`Kubernetes` version, we recommend that you use this option.
+
Use _access entries_ to manage the [.noloc]`Kubernetes` permissions of IAM principals from outside the cluster. You can add and manage access to the cluster by using the EKS API, {aws} Command Line Interface, {aws} SDKs, {aws} CloudFormation, and {aws-management-console}. This means you can manage users with the same tools that you created the cluster with.
+
To get started, follow <<setting-up-access-entries,Change authentication mode to use access entries>>, then <<migrating-access-entries,Migrating existing aws-auth ConfigMap entries to access entries>>.
* *Adding entries to the `aws-auth` `ConfigMap`*
 – If your cluster's platform version is earlier than the version listed in the  <<access-entries,Prerequisites>> section, then you must use this option. If your cluster's platform version is at or later than the platform version listed in the <<access-entries,Prerequisites>> section for your cluster's [.noloc]`Kubernetes` version, and you've added entries to the `ConfigMap`, then we recommend that you migrate those entries to access entries. You can't migrate entries that Amazon EKS added to the `ConfigMap` however, such as entries for IAM roles used with managed node groups or Fargate profiles. For more information, see <<grant-k8s-access>>.
+
** If you have to use the `aws-auth` `ConfigMap` option, you can add entries to the `ConfigMap` using the `eksctl create iamidentitymapping` command. For more information, see https://eksctl.io/usage/iam-identity-mappings/[Manage IAM users and roles] in the `eksctl` documentation.


[[set-cam,set-cam.title]]
== Set Cluster Authentication Mode

Each cluster has an  _authentication mode_. The authentication mode determines which methods you can use to allow IAM principals to access [.noloc]`Kubernetes` objects on your cluster. There are three authentication modes.

[IMPORTANT]
====

Once the access entry method is enabled, it cannot be disabled. 

If the `ConfigMap` method is not enabled during cluster creation, it cannot be enabled later. All clusters created before the introduction of access entries have the `ConfigMap` method enabled. 

====

*The `aws-auth` `ConfigMap` inside the cluster*::
This is the original authentication mode for Amazon EKS clusters. The IAM principal that created the cluster is the initial user that can access the cluster by using `kubectl`. The initial user must add other users to the list in the `aws-auth` `ConfigMap` and assign permissions that affect the other users within the cluster. These other users can't manage or remove the initial user, as there isn't an entry in the `ConfigMap` to manage.


*Both the `ConfigMap` and access entries*::
With this authentication mode, you can use both methods to add IAM principals to the cluster. Note that each method stores separate entries; for example, if you add an access entry from the {aws} CLI, the `aws-auth` `ConfigMap` is not updated.


*Access entries only*::
With this authentication mode, you can use the EKS API, {aws} Command Line Interface, {aws} SDKs, {aws} CloudFormation, and {aws-management-console} to manage access to the cluster for IAM principals.
+
Each access entry has a _type_ and you can use the combination of an _access scope_ to limit the principal to a specific namespace and an _access policy_ to set preconfigured reusable permissions policies. Alternatively, you can use the [.noloc]`STANDARD` type and [.noloc]`Kubernetes` [.noloc]`RBAC` groups to assign custom permissions.


[cols="1,1", options="header"]
|===
|Authentication mode
|Methods


|`ConfigMap` only (`CONFIG_MAP`)
|`aws-auth` `ConfigMap`

|EKS API and `ConfigMap` (`API_AND_CONFIG_MAP`)
|access entries in the EKS API, {aws} Command Line Interface, {aws} SDKs, {aws} CloudFormation, and {aws-management-console} and `aws-auth` `ConfigMap`

|EKS API only (`API`)
|access entries in the EKS API, {aws} Command Line Interface, {aws} SDKs, {aws} CloudFormation, and {aws-management-console}
|===

[.topic]
[[access-entries,access-entries.title]]
== Grant [.noloc]`IAM` users access to [.noloc]`Kubernetes` with EKS access entries

[abstract]
--
Learn how to manage access entries for IAM principals to your Amazon EKS cluster, including creating, updating, and deleting access entries for fine-grained authentication and authorization.
--

* Familiarity with cluster access options for your Amazon EKS cluster. For more information, see <<grant-k8s-access>>.
* An existing Amazon EKS cluster. To deploy one, see <<getting-started>>. To use _access entries_ and change the authentication mode of a cluster, the cluster must have a platform version that is the same or later than the version listed in the following table, or a [.noloc]`Kubernetes` version that is later than the versions listed in the table.
+
[cols="1,1", options="header"]
|===
|Kubernetes version
|Platform version


|`1.30`
|`eks.2`

|`1.29`
|`eks.1`

|`1.28`
|`eks.6`

|`1.27`
|`eks.10`

|`1.26`
|`eks.11`

|`1.25`
|`eks.12`

|`1.24`
|`eks.15`

|`1.23`
|`eks.17`
|===
+
You can check your current [.noloc]`Kubernetes` and platform version by replacing [.replaceable]`my-cluster` in the following command with the name of your cluster and then running the modified command: ``aws eks describe-cluster --name [.replaceable]`my-cluster` --query 'cluster.{"Kubernetes_Version": version, "Platform_Version": platformVersion}'``.
+
IMPORTANT: After Amazon EKS updates your cluster to the platform version listed in the table, Amazon EKS creates an access entry with administrator permissions to the cluster for the IAM principal that originally created the cluster. If you don't want that IAM principal to have administrator permissions to the cluster, remove the access entry that Amazon EKS created.

For clusters with platform versions that are earlier than those listed in the previous table, the cluster creator is always a cluster administrator. It's not possible to remove cluster administrator permissions from the IAM user or role that created the cluster.
* An IAM principal with the following permissions for your cluster: `CreateAccessEntry`, `ListAccessEntries`, `DescribeAccessEntry`, `DeleteAccessEntry`, and `UpdateAccessEntry`. For more information about Amazon EKS permissions, see  link:service-authorization/latest/reference/list_amazonelastickubernetesservice.html#amazonelastickubernetesservice-actions-as-permissions[Actions defined by Amazon Elastic Kubernetes Service,type="documentation"] in the Service Authorization Reference.
* An existing IAM principal to create an access entry for, or an existing access entry to update or delete.


[.topic]
[[setting-up-access-entries,setting-up-access-entries.title]]
=== Change authentication mode to use access entries

To begin using access entries, you must change the authentication mode of the cluster to either the `API_AND_CONFIG_MAP` or `API` modes. This adds the API for access entries.


[[access-entries-setup-console,access-entries-setup-console.title]]
==== {aws} Console

. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Choose the name of the cluster that you want to create an access entry in.
. Choose the *Access* tab.
. The *Authentication mode* shows the current authentication mode of the cluster. If the mode says [.noloc]`EKS API`, you can already add access entries and you can skip the remaining steps.
. Choose *Manage access*.
. For *Cluster authentication mode*, select a mode with the [.noloc]`EKS API`. Note that you can't change the authentication mode back to a mode that removes the [.noloc]`EKS API` and access entries.
. Choose *Save changes*. Amazon EKS begins to update the cluster, the status of the cluster changes to [.noloc]`Updating`, and the change is recorded in the  *Update history* tab.
. Wait for the status of the cluster to return to [.noloc]`Active`. When the cluster is [.noloc]`Active`, you can follow the steps in  <<creating-access-entries>> to add access to the cluster for IAM principals.

[[access-setup-cli,access-setup-cli.title]]
==== {aws} CLI

. Install the {aws} CLI, as described in  link:cli/latest/userguide/cli-chap-install.html[Installing, updating, and uninstalling the {aws} CLI,type="documentation"] in the {aws} Command Line Interface User Guide.
. Run the following command. Replace [.replaceable]`my-cluster` with the name of your cluster. If you want to disable the `ConfigMap` method permanently, replace `API_AND_CONFIG_MAP` with `API`.
+
Amazon EKS begins to update the cluster, the status of the cluster changes to [.noloc]`UPDATING`, and the change is recorded in the  [command]*aws eks list-updates*.
+
[source,bash]
----
aws eks update-cluster-config --name my-cluster --access-config authenticationMode=API_AND_CONFIG_MAP
----
. Wait for the status of the cluster to return to [.noloc]`Active`. When the cluster is [.noloc]`Active`, you can follow the steps in  <<creating-access-entries>> to add access to the cluster for IAM principals.


[.topic]
[[creating-access-entries,creating-access-entries.title]]
=== Create access entries


Before creating access entries, consider the following:

* A properly set authentication mode. See <<setting-up-access-entries>>.
* An _access entry_ includes the Amazon Resource Name (ARN) of one, and only one, existing IAM principal. An IAM principal can't be included in more than one access entry. Additional considerations for the ARN that you specify:
+
** IAM best practices recommend accessing your cluster using IAM _roles_ that have short-term credentials, rather than IAM _users_ that have long-term credentials. For more information, see  link:IAM/latest/UserGuide/best-practices.html#bp-users-federation-idp[Require human users to use federation with an identity provider to access {aws} using temporary credentials,type="documentation"] in the IAM User Guide.
** If the ARN is for an IAM role, it _can_ include a path. ARNs in `aws-auth` `ConfigMap` entries, _can't_ include a path. For example, your ARN can be `{arn-aws}iam::<111122223333>:role/<development/apps/my-role>` or `{arn-aws}iam::<111122223333>:role/<my-role>`.
** If the type of the access entry is anything other than `STANDARD` (see next consideration about types), the ARN must be in the same {aws} account that your cluster is in. If the type is `STANDARD`, the ARN can be in the same, or different, {aws} account than the account that your cluster is in.
** You can't change the IAM principal after the access entry is created.
** If you ever delete the IAM principal with this ARN, the access entry isn't automatically deleted. We recommend that you delete the access entry with an ARN for an IAM principal that you delete. If you don't delete the access entry and ever recreate the IAM principal, even if it has the same ARN, the access entry won't work. This is because even though the ARN is the same for the recreated IAM principal, the `roleID` or `userID` (you can see this with the `aws sts get-caller-identity` {aws} CLI command) is different for the recreated IAM principal than it was for the original IAM principal. Even though you don't see the IAM principal's `roleID` or `userID` for an access entry, Amazon EKS stores it with the access entry.
* Each access entry has a _type_. You can specify `EC2_Linux` (for an IAM role used with Linux or Bottlerocket self-managed nodes), `EC2_Windows` (for an IAM roles used with Windows self-managed nodes), `FARGATE_LINUX` (for an IAM roles used with {aws} Fargate (Fargate)), or `STANDARD` as a type. If you don't specify a type, Amazon EKS automatically sets the type to `STANDARD`. It's unnecessary to create an access entry for an IAM role that's used for a managed node group or a Fargate profile, because Amazon EKS adds entries for these roles to the `aws-auth` `ConfigMap`, regardless of which platform version your cluster is at. 
+
You can't change the type after the access entry is created.
* If the type of the access entry is `STANDARD`, you can specify a _username_ for the access entry. If you don't specify a value for username, Amazon EKS sets one of the following values for you, depending on the type of the access entry and whether the IAM principal that you specified is an IAM role or IAM user. Unless you have a specific reason for specifying your own username, we recommend that don't specify one and let Amazon EKS auto-generate it for you. If you specify your own username:
+
** It can't start with `system:`, `eks:`, `aws:`, `amazon:`, or `iam:`.
** If the username is for an IAM role, we recommend that you add `{{SessionName}}` to the end of your username. If you add `{{SessionName}}` to your username, the username must include a colon _before_ {{SessionName}}. When this role is assumed, the name of the session specified when assuming the role is automatically passed to the cluster and will appear in CloudTrail logs. For example, you can't have a username of `john{{SessionName}}`. The username would have to be `:john{{SessionName}}` or `jo:hn{{SessionName}}`. The colon only has to be before `{{SessionName}}`. The username generated by Amazon EKS in the following table includes an ARN. Since an ARN includes colons, it meets this requirement. The colon isn't required if you don't include `{{SessionName}}` in your username.
+
[cols="1,1,1", options="header"]
|===
|IAM principal type
|Type
|Username value that Amazon EKS automatically sets


|User
|`STANDARD`
|

The ARN of the user. Example: `{arn-aws}iam::<111122223333>:user/<my-user>`

|Role
|`STANDARD`
|

The STS ARN of the role when it's assumed. Amazon EKS appends `{{SessionName}}` to the role. 

Example: `{arn-aws}sts::<111122223333>:assumed-role/<my-role>/{{SessionName}}`

If the ARN of the role that you specified contained a path, Amazon EKS removes it in the generated username.

|Role
|`EC2_Linux` or `EC2_Windows`
|

`system:node:{{EC2PrivateDNSName}}`

|Role
|`FARGATE_LINUX`
|

`system:node:{{SessionName}}`
|===
+
You can change the username after the access entry is created.
* If an access entry's type is `STANDARD`, and you want to use [.noloc]`Kubernetes` RBAC authorization, you can add one or more  _group names_ to the access entry. After you create an access entry you can add and remove group names. For the IAM principal to have access to [.noloc]`Kubernetes` objects on your cluster, you must create and manage [.noloc]`Kubernetes` role-based authorization (RBAC) objects. Create [.noloc]`Kubernetes` `RoleBinding` or `ClusterRoleBinding` objects on your cluster that specify the group name as a `subject` for `kind: Group`. [.noloc]`Kubernetes` authorizes the IAM principal access to any cluster objects that you've specified in a [.noloc]`Kubernetes` `Role` or `ClusterRole` object that you've also specified in your binding's `roleRef`. If you specify group names, we recommend that you're familiar with the [.noloc]`Kubernetes` role-based authorization (RBAC) objects. For more information, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/[Using RBAC Authorization] in the [.noloc]`Kubernetes` documentation.  
+
IMPORTANT: Amazon EKS doesn't confirm that any [.noloc]`Kubernetes` RBAC objects that exist on your cluster include any of the group names that you specify.
+
Instead of, or in addition to, [.noloc]`Kubernetes` authorizing the IAM principal access to [.noloc]`Kubernetes` objects on your cluster, you can associate Amazon EKS  _access policies_ to an access entry. Amazon EKS authorizes IAM principals to access [.noloc]`Kubernetes` objects on your cluster with the permissions in the access policy. You can scope an access policy's permissions to [.noloc]`Kubernetes` namespaces that you specify. Use of access policies don't require you to manage [.noloc]`Kubernetes` RBAC objects. For more information, see <<access-policies>>.
* If you create an access entry with type `EC2_Linux` or `EC2_Windows`, the IAM principal creating the access entry must have the `iam:PassRole` permission. For more information, see  link:IAM/latest/UserGuide/id_roles_use_passrole.html[Granting a user permissions to pass a role to an {aws} service,type="documentation"] in the IAM User Guide.
* Similar to standard  link:IAM/latest/UserGuide/troubleshoot_general.html#troubleshoot_general_eventual-consistency[IAM behavior,type="documentation"], access entry creation and updates are eventually consistent, and may take several seconds to be effective after the initial API call returns successfully. You must design your applications to account for these potential delays. We recommend that you don't include access entry creates or updates in the critical, high- availability code paths of your application. Instead, make changes in a separate initialization or setup routine that you run less frequently. Also, be sure to verify that the changes have been propagated before production workflows depend on them. 
* Access entries do not support link:IAM/latest/UserGuide/using-service-linked-roles.html[service linked roles,type="documentation"]. You cannot create access entries where the principal ARN is a service linked role. You can identify service linked roles by their ARN, which is in the format `{arn-aws}iam::*:role/aws-service-role/*`. 

You can create an access entry using the {aws-management-console} or the {aws} CLI.


[[access-create-console,access-create-console.title]]
==== {aws-management-console} 
. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Choose the name of the cluster that you want to create an access entry in.
. Choose the *Access* tab.
. Choose *Create access entry*.
. For *IAM principal*, select an existing IAM role or user. IAM best practices recommend accessing your cluster using IAM  _roles_ that have short-term credentials, rather than IAM _users_ that have long-term credentials. For more information, see  link:IAM/latest/UserGuide/best-practices.html#bp-users-federation-idp[Require human users to use federation with an identity provider to access {aws} using temporary credentials,type="documentation"] in the IAM User Guide.
. For *Type*, if the access entry is for the node role used for self-managed Amazon EC2 nodes, select  *EC2 Linux* or  *EC2 Windows*. Otherwise, accept the default (*Standard*).
. If the *Type* you chose is  *Standard* and you want to specify a  *Username*, enter the username.
. If the *Type* you chose is  *Standard* and you want to use [.noloc]`Kubernetes` RBAC authorization for the IAM principal, specify one or more names for  *Groups*. If you don't specify any group names and want to use Amazon EKS authorization, you can associate an access policy in a later step, or after the access entry is created.
. (Optional) For *Tags*, assign labels to the access entry. For example, to make it easier to find all resources with the same tag.
. Choose *Next*.
. On the *Add access policy* page, if the type you chose was  *Standard* and you want Amazon EKS to authorize the IAM principal to have permissions to the [.noloc]`Kubernetes` objects on your cluster, complete the following steps. Otherwise, choose  *Next*.
+
.. For *Policy name*, choose an access policy. You can't view the permissions of the access policies, but they include similar permissions to those in the [.noloc]`Kubernetes` user-facing `ClusterRole` objects. For more information, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles[User-facing roles] in the [.noloc]`Kubernetes` documentation.
.. Choose one of the following options:
+
*** *Cluster* – Choose this option if you want Amazon EKS to authorize the IAM principal to have the permissions in the access policy for all [.noloc]`Kubernetes` objects on your cluster.
*** *[.noloc]`Kubernetes` namespace* – Choose this option if you want Amazon EKS to authorize the IAM principal to have the permissions in the access policy for all [.noloc]`Kubernetes` objects in a specific [.noloc]`Kubernetes` namespace on your cluster. For  *Namespace*, enter the name of the [.noloc]`Kubernetes` namespace on your cluster. If you want to add additional namespaces, choose  *Add new namespace* and enter the namespace name.
.. If you want to add additional policies, choose *Add policy*. You can scope each policy differently, but you can add each policy only once.
.. Choose *Next*.
. Review the configuration for your access entry. If anything looks incorrect, choose *Previous* to go back through the steps and correct the error. If the configuration is correct, choose  *Create*.

[[access-create-cli,access-create-cli.title]]
==== {aws} CLI

. Install the {aws} CLI, as described in  link:cli/latest/userguide/cli-chap-install.html[Installing, updating, and uninstalling the {aws} CLI,type="documentation"] in the {aws} Command Line Interface User Guide.
. To create an access entry
You can use any of the following examples to create access entries:
+
** Create an access entry for a self-managed Amazon EC2 Linux node group. Replace [.replaceable]`my-cluster` with the name of your cluster, [.replaceable]`111122223333` with your {aws} account ID, and [.replaceable]`EKS-my-cluster-self-managed-ng-1` with the name of your <<create-node-role,node IAM role>>. If your node group is a Windows node group, then replace [.replaceable]`EC2_Linux` with `EC2_Windows`.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks create-access-entry --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/EKS-my-cluster-self-managed-ng-1 --type EC2_Linux
----
+
You can't use the `--kubernetes-groups` option when you specify a type other than `STANDARD`. You can't associate an access policy to this access entry, because its type is a value other than `STANDARD`.
** Create an access entry that allows an IAM role that's not used for an Amazon EC2 self-managed node group, that you want [.noloc]`Kubernetes` to authorize access to your cluster with. Replace [.replaceable]`my-cluster` with the name of your cluster, [.replaceable]`111122223333` with your {aws} account ID, and [.replaceable]`my-role` with the name of your IAM role. Replace [.replaceable]`Viewers` with the name of a group that you've specified in a [.noloc]`Kubernetes` `RoleBinding` or `ClusterRoleBinding` object on your cluster.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks create-access-entry --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/my-role --type STANDARD --user Viewers --kubernetes-groups Viewers
----
** Create an access entry that allows an IAM user to authenticate to your cluster. This example is provided because this is possible, though IAM best practices recommend accessing your cluster using IAM _roles_ that have short-term credentials, rather than IAM _users_ that have long-term credentials. For more information, see  link:IAM/latest/UserGuide/best-practices.html#bp-users-federation-idp[Require human users to use federation with an identity provider to access {aws} using temporary credentials,type="documentation"] in the IAM User Guide.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks create-access-entry --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:user/my-user --type STANDARD --username my-user
----
+
If you want this user to have more access to your cluster than the permissions in the [.noloc]`Kubernetes` API discovery roles, then you need to associate an access policy to the access entry, since the `--kubernetes-groups` option isn't used. For more information, see <<access-policies>> and https://kubernetes.io/docs/reference/access-authn-authz/rbac/#discovery-roles[API discovery roles] in the [.noloc]`Kubernetes` documentation.


[.topic]
[[updating-access-entries,updating-access-entries.title]]
=== Update access entries

You can update an access entry using the {aws-management-console} or the {aws} CLI.


[[access-update-console,access-update-console.title]]
==== {aws-management-console}
. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Choose the name of the cluster that you want to create an access entry in.
. Choose the *Access* tab.
. Choose the access entry that you want to update.
. Choose *Edit*.
. For *Username*, you can change the existing value.
. For *Groups*, you can remove existing group names or add new group names. If the following groups names exist, don't remove them:  *system:nodes* or  *system:bootstrappers*. Removing these groups can cause your cluster to function improperly. If you don't specify any group names and want to use Amazon EKS authorization, associate an  xref:access-policies[access policy,linkend=access-policies] in a later step.
. For *Tags*, you can assign labels to the access entry. For example, to make it easier to find all resources with the same tag. You can also remove existing tags.
. Choose *Save changes*.
. If you want to associate an access policy to the entry, see <<access-policies>>.

[[access-update-cli,access-update-cli.title]]
==== {aws} CLI
. Install the {aws} CLI, as described in  link:cli/latest/userguide/cli-chap-install.html[Installing, updating, and uninstalling the {aws} CLI,type="documentation"] in the {aws} Command Line Interface User Guide.
. To update an access entry
Replace [.replaceable]`my-cluster` with the name of your cluster, [.replaceable]`111122223333` with your {aws} account ID, and [.replaceable]`EKS-my-cluster-my-namespace-Viewers` with the name of an IAM role.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks update-access-entry --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/EKS-my-cluster-my-namespace-Viewers --kubernetes-groups Viewers
----
+
You can't use the `--kubernetes-groups` option if the type of the access entry is a value other than `STANDARD`. You also can't associate an access policy to an access entry with a type other than `STANDARD`. 


[.topic]
[[deleting-access-entries,deleting-access-entries.title]]
=== Delete access entries

If you discover that you deleted an access entry in error, you can always recreate it. If the access entry that you're deleting is associated to any access policies, the associations are automatically deleted. You don't have to disassociate access policies from an access entry before deleting the access entry.

You can delete an access entry using the {aws-management-console} or the {aws} CLI.


[[access-delete-console,access-delete-console.title]]
==== {aws-management-console}
. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Choose the name of the cluster that you want to delete an access entry from.
. Choose the *Access* tab.
. In the *Access entries* list, choose the access entry that you want to delete.
. Choose Delete.
. In the confirmation dialog box, choose *Delete*.

[[access-delete-cli,access-delete-cli.title]]
==== {aws} CLI
. Install the {aws} CLI, as described in  link:cli/latest/userguide/cli-chap-install.html[Installing, updating, and uninstalling the {aws} CLI,type="documentation"] in the {aws} Command Line Interface User Guide.
. To delete an access entry
Replace [.replaceable]`my-cluster` with the name of your cluster, [.replaceable]`111122223333` with your {aws} account ID, and [.replaceable]`my-role` with the name of the IAM role that you no longer want to have access to your cluster.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks delete-access-entry --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/my-role
----


[.topic]
[[access-policies,access-policies.title]]
== Associate access policies with access entries

[abstract]
--
Learn how to associate and disassociate Amazon EKS access policies to and from access entries to grant Kubernetes permissions to IAM principals.
--

You can assign one or more access policies to  _access entries_ of _type_``STANDARD``. Amazon EKS automatically grants the other types of access entries the permissions required to function properly in your cluster. Amazon EKS access policies include [.noloc]`Kubernetes` permissions, not IAM permissions. Before associating an access policy to an access entry, make sure that you're familiar with the [.noloc]`Kubernetes` permissions included in each access policy. For more information, see <<access-policy-permissions>>. If none of the access policies meet your requirements, then don't associate an access policy to an access entry. Instead, specify one or more _group names_ for the access entry and create and manage [.noloc]`Kubernetes` role-based access control objects. For more information, see <<creating-access-entries>>.



* An existing access entry. To create one, see <<creating-access-entries>>.
* An {aws} Identity and Access Management role or user with the following permissions: `ListAccessEntries`, `DescribeAccessEntry`, `UpdateAccessEntry`, `ListAccessPolicies`, `AssociateAccessPolicy`, and `DisassociateAccessPolicy`. For more information, see  link:service-authorization/latest/reference/list_amazonelastickubernetesservice.html#amazonelastickubernetesservice-actions-as-permissions[Actions defined by Amazon Elastic Kubernetes Service,type="documentation"] in the Service Authorization Reference.

Before associating access policies with access entries, consider the following requirements:



* You can associate multiple access policies to each access entry, but you can only associate each policy to an access entry once. If you associate multiple access policies, the access entry's IAM principal has all permissions included in all associated access policies.
* You can scope an access policy to all resources on a cluster or by specifying the name of one or more [.noloc]`Kubernetes` namespaces. You can use wildcard characters for a namespace name. For example, if you want to scope an access policy to all namespaces that start with `dev-`, you can specify `dev-*` as a namespace name. Make sure that the namespaces exist on your cluster and that your spelling matches the actual namespace name on the cluster. Amazon EKS doesn't confirm the spelling or existence of the namespaces on your cluster.
* You can change the _access scope_ for an access policy after you associate it to an access entry. If you've scoped the access policy to [.noloc]`Kubernetes` namespaces, you can add and remove namespaces for the association, as necessary.
* If you associate an access policy to an access entry that also has _group names_ specified, then the IAM principal has all the permissions in all associated access policies. It also has all the permissions in any [.noloc]`Kubernetes` `Role` or `ClusterRole` object that is specified in any [.noloc]`Kubernetes` `Role` and `RoleBinding` objects that specify the group names.
* If you run the `kubectl auth can-i --list` command, you won't see any [.noloc]`Kubernetes` permissions assigned by access policies associated with an access entry for the IAM principal you're using when you run the command. The command only shows [.noloc]`Kubernetes` permissions if you've granted them in [.noloc]`Kubernetes` `Role` or `ClusterRole` objects that you've bound to the group names or username that you specified for an access entry.
* If you impersonate a [.noloc]`Kubernetes` user or group when interacting with [.noloc]`Kubernetes` objects on your cluster, such as using the `kubectl` command with `--as [.replaceable]`username`` or ``--as-group [.replaceable]`group-name```, you're forcing the use of [.noloc]`Kubernetes` RBAC authorization. As a result, the IAM principal has no permissions assigned by any access policies associated to the access entry. The only [.noloc]`Kubernetes` permissions that the user or group that the IAM principal is impersonating has are the [.noloc]`Kubernetes` permissions that you've granted them in [.noloc]`Kubernetes` `Role` or `ClusterRole` objects that you've bound to the group names or user name. For your IAM principal to have the permissions in associated access policies, don't impersonate a [.noloc]`Kubernetes` user or group. The IAM principal will still also have any permissions that you've granted them in the [.noloc]`Kubernetes` `Role` or `ClusterRole` objects that you've bound to the group names or user name that you specified for the access entry. For more information, see https://kubernetes.io/docs/reference/access-authn-authz/authentication/#user-impersonation[User impersonation] in the [.noloc]`Kubernetes` documentation.

You can associate an access policy to an access entry using the {aws-management-console} or the {aws} CLI.


[[access-associate-console,access-associate-console.title]]
=== {aws-management-console}
. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Choose the name of the cluster that has an access entry that you want to associate an access policy to.
. Choose the *Access* tab.
. If the type of the access entry is *Standard*, you can associate or disassociate Amazon EKS  *access policies*. If the type of your access entry is anything other than  *Standard*, then this option isn't available.
. Choose *Associate access policy*.
. For *Policy name*, select the policy with the permissions you want the IAM principal to have. To view the permissions included in each policy, see <<access-policy-permissions>>.
. For *Access scope*, choose an access scope. If you choose  *Cluster*, the permissions in the access policy are granted to the IAM principal for resources in all [.noloc]`Kubernetes` namespaces. If you choose  *[.noloc]`Kubernetes` namespace*, you can then choose  *Add new namespace*. In the  *Namespace* field that appears, you can enter the name of a [.noloc]`Kubernetes` namespace on your cluster. If you want the IAM principal to have the permissions across multiple namespaces, then you can enter multiple namespaces.
. Choose *Add access policy*.

[[access-associate-cli,access-associate-cli.title]]
=== {aws} CLI
. Version `2.12.3` or later or version `1.27.160` or later of the {aws} Command Line Interface ({aws} CLI) installed and configured on your device or {aws} CloudShell. To check your current version, use `aws --version | cut -d / -f2 | cut -d ' ' -f1`. Package managers such `yum`, `apt-get`, or [.noloc]`Homebrew` for [.noloc]`macOS` are often several versions behind the latest version of the {aws} CLI. To install the latest version, see   link:cli/latest/userguide/cli-chap-install.html[Installing, updating, and uninstalling the {aws} CLI,type="documentation"] and  link:cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-config[Quick configuration with aws configure,type="documentation"] in the _{aws} Command Line Interface User Guide_. The {aws} CLI version that is installed in {aws} CloudShell might also be several versions behind the latest version. To update it, see  link:cloudshell/latest/userguide/vm-specs.html#install-cli-software[Installing {aws} CLI to your home directory,type="documentation"] in the _{aws} CloudShell User Guide_.
+
. View the available access policies.
+
[source,bash]
----
aws eks list-access-policies --output table
----
+
An example output is as follows.
+
[source,bash]
----
---------------------------------------------------------------------------------------------------------
|                                          ListAccessPolicies                                           |
+-------------------------------------------------------------------------------------------------------+
||                                           accessPolicies                                            ||
|+---------------------------------------------------------------------+-------------------------------+|
||                                 arn                                 |             name              ||
|+---------------------------------------------------------------------+-------------------------------+|
||  {arn-aws}eks::aws:cluster-access-policy/AmazonEKSAdminPolicy        |  AmazonEKSAdminPolicy         ||
||  {arn-aws}eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy |  AmazonEKSClusterAdminPolicy  ||
||  {arn-aws}eks::aws:cluster-access-policy/AmazonEKSEditPolicy         |  AmazonEKSEditPolicy          ||
||  {arn-aws}eks::aws:cluster-access-policy/AmazonEKSViewPolicy         |  AmazonEKSViewPolicy          ||
|+---------------------------------------------------------------------+-------------------------------+|

----
+
To view the permissions included in each policy, see <<access-policy-permissions>>.
. View your existing access entries. Replace [.replaceable]`my-cluster` with the name of your cluster.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks list-access-entries --cluster-name my-cluster
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
{
    "accessEntries": [
        "{arn-aws}iam::111122223333:role/my-role",
        "{arn-aws}iam::111122223333:user/my-user"
    ]
}
----
. Associate an access policy to an access entry. The following example associates the `AmazonEKSViewPolicy` access policy to an access entry. Whenever the [.replaceable]`my-role` IAM role attempts to access [.noloc]`Kubernetes` objects on the cluster, Amazon EKS will authorize the role to use the permissions in the policy to access [.noloc]`Kubernetes` objects in the [.replaceable]`my-namespace1` and [.replaceable]`my-namespace2` [.noloc]`Kubernetes` namespaces only. Replace [.replaceable]`my-cluster` with the name of your cluster, [.replaceable]`111122223333` with your {aws} account ID, and [.replaceable]`my-role` with the name of the IAM role that you want Amazon EKS to authorize access to [.noloc]`Kubernetes` cluster objects for.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks associate-access-policy --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/my-role \
    --access-scope type=namespace,namespaces=my-namespace1,my-namespace2 --policy-arn {arn-aws}eks::aws:cluster-access-policy/AmazonEKSViewPolicy
----
+
If you want the IAM principal to have the permissions cluster-wide, replace `type=namespace,namespaces=[.replaceable]``my-namespace1``,[.replaceable]``my-namespace2``` with `type=cluster`. If you want to associate multiple access policies to the access entry, run the command multiple times, each with a unique access policy. Each associated access policy has its own scope.
+
NOTE: If you later want to change the scope of an associated access policy, run the previous command again with the new scope. For example, if you wanted to remove [.replaceable]`my-namespace2`, you'd run the command again using `type=namespace,namespaces=[.replaceable]``my-namespace1``` only. If you wanted to change the scope from `namespace` to `cluster`, you'd run the command again using `type=cluster`, removing `type=namespace,namespaces=[.replaceable]``my-namespace1``,[.replaceable]``my-namespace2```.
. Determine which access policies are associated to an access entry.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks list-associated-access-policies --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/my-role
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
{
    "clusterName": "my-cluster",
    "principalArn": "{arn-aws}iam::111122223333",
    "associatedAccessPolicies": [
        {
            "policyArn": "{arn-aws}eks::aws:cluster-access-policy/AmazonEKSViewPolicy",
            "accessScope": {
                "type": "cluster",
                "namespaces": []
            },
            "associatedAt": "2023-04-17T15:25:21.675000-04:00",
            "modifiedAt": "2023-04-17T15:25:21.675000-04:00"
        },
        {
            "policyArn": "{arn-aws}eks::aws:cluster-access-policy/AmazonEKSAdminPolicy",
            "accessScope": {
                "type": "namespace",
                "namespaces": [
                    "my-namespace1",
                    "my-namespace2"
                ]
            },
            "associatedAt": "2023-04-17T15:02:06.511000-04:00",
            "modifiedAt": "2023-04-17T15:02:06.511000-04:00"
        }
    ]
}
----
+
In the previous example, the IAM principal for this access entry has view permissions across all namespaces on the cluster, and administrator permissions to two [.noloc]`Kubernetes` namespaces.  
. Disassociate an access policy from an access entry. In this example, the `AmazonEKSAdminPolicy` policy is disassociated from an access entry. The IAM principal retains the permissions in the `AmazonEKSViewPolicy` access policy for objects in the [.replaceable]`my-namespace1` and [.replaceable]`my-namespace2` namespaces however, because that access policy is not disassociated from the access entry.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
aws eks disassociate-access-policy --cluster-name my-cluster --principal-arn {arn-aws}iam::111122223333:role/my-role \
    --policy-arn {arn-aws}eks::aws:cluster-access-policy/AmazonEKSAdminPolicy
----


[[access-policy-permissions,access-policy-permissions.title]]
=== Access policy permissions

Access policies include `rules` that contain [.noloc]`Kubernetes` `verbs` (permissions) and `resources`. Access policies don't include IAM permissions or resources. Similar to [.noloc]`Kubernetes` `Role` and `ClusterRole` objects, access policies only include `allow` `rules`. You can't modify the contents of an access policy. You can't create your own access policies. If the permissions in the access policies don't meet your needs, then create [.noloc]`Kubernetes` RBAC objects and specify  _group names_ for your access entries. For more information, see <<creating-access-entries>>. The permissions contained in access policies are similar to the permissions in the [.noloc]`Kubernetes` user-facing cluster roles. For more information, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles[User-facing roles] in the [.noloc]`Kubernetes` documentation.  

Choose any access policy to see its contents. Each row of each table in each access policy is a separate rule.


[[access-policy-permissions-amazoneksadminpolicy,access-policy-permissions-amazoneksadminpolicy.title]]
.AmazonEKSAdminPolicy
[%collapsible]
====

This access policy includes permissions that grant an IAM principal most permissions to resources. When associated to an access entry, its access scope is typically one or more [.noloc]`Kubernetes` namespaces. If you want an IAM principal to have administrator access to all resources on your cluster, associate the  <<access-policy-permissions-amazoneksclusteradminpolicy,AmazonEKSClusterAdminPolicy>> access policy to your access entry instead.

*ARN* – `{arn-aws}eks::aws:cluster-access-policy/AmazonEKSAdminPolicy`

[cols="1,1,1", options="header"]
|===
|Kubernetes API groups
|Kubernetes resources
|Kubernetes verbs (permissions)


|`apps`
|`daemonsets`, `deployments`, `deployments/rollback`, `deployments/scale`, `replicasets`, `replicasets/scale`, `statefulsets`, `statefulsets/scale`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`apps`
|`controllerrevisions`, `daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `replicasets`, `replicasets/scale`, `replicasets/status`, `statefulsets`, `statefulsets/scale`, `statefulsets/status`
|`get`, `list`, `watch`

|`authorization.k8s.io`
|`localsubjectaccessreviews`
|`create`

|`autoscaling`
|`horizontalpodautoscalers`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`autoscaling`
|`horizontalpodautoscalers`, `horizontalpodautoscalers/status`
|`get`, `list`, `watch`

|`batch`
|`cronjobs`, `jobs`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`batch`
|`cronjobs`, `cronjobs/status`, `jobs`, `jobs/status`
|`get`, `list`, `watch`

|`discovery.k8s.io`
|`endpointslices`
|`get`, `list`, `watch`

|`extensions`
|`daemonsets`, `deployments`, `deployments/rollback`, `deployments/scale`, `ingresses`, `networkpolicies`, `replicasets`, `replicasets/scale`, `replicationcontrollers/scale`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`extensions`
|`daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `ingresses`, `ingresses/status`, `networkpolicies`, `replicasets`, `replicasets/scale`, `replicasets/status`, `replicationcontrollers/scale`
|`get`, `list`, `watch`

|`networking.k8s.io`
|`ingresses`, `ingresses/status`, `networkpolicies`
|`get`, `list`, `watch`

|`networking.k8s.io`
|`ingresses`, `networkpolicies`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`policy`
|`poddisruptionbudgets`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`policy`
|`poddisruptionbudgets`, `poddisruptionbudgets/status`
|`get`, `list`, `watch`

|`rbac.authorization.k8s.io`
|`rolebindings`, `roles`
|`create`, `delete`, `deletecollection`, `get`, `list`, `patch`, `update`, `watch`

|
|`configmaps`, `endpoints`, `persistentvolumeclaims`, `persistentvolumeclaims/status`, `pods`, `replicationcontrollers`, `replicationcontrollers/scale`, `serviceaccounts`, `services`, `services/status`
|`get`,``list``, `watch`

|
|``pods/attach``, `pods/exec`, `pods/portforward`, `pods/proxy`, `secrets`, `services/proxy`
|`get`, `list`, `watch`

|
|`configmaps`, `events`, `persistentvolumeclaims`, `replicationcontrollers`, `replicationcontrollers/scale`, `secrets`, `serviceaccounts`, `services`, `services/proxy`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|
|`pods`, `pods/attach`, `pods/exec`, `pods/portforward`, `pods/proxy`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|
|`serviceaccounts`
|`impersonate`

|
|`bindings`, `events`, `limitranges`, `namespaces/status`, `pods/log`, `pods/status`, `replicationcontrollers/status`, `resourcequotas`, `resourcequotas/status`
|`get`, `list`, `watch`

|
|`namespaces`
|`get`,``list``, `watch`
|===
====

[[access-policy-permissions-amazoneksclusteradminpolicy,access-policy-permissions-amazoneksclusteradminpolicy.title]]
.AmazonEKSClusterAdminPolicy
[%collapsible]
====

This access policy includes permissions that grant an IAM principal administrator access to a cluster. When associated to an access entry, its access scope is typically the cluster, rather than a [.noloc]`Kubernetes` namespace. If you want an IAM principal to have a more limited administrative scope, consider associating the  <<access-policy-permissions-amazoneksadminpolicy,AmazonEKSAdminPolicy>> access policy to your access entry instead.

*ARN* – `{arn-aws}eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy`

[cols="1,1,1,1", options="header"]
|===
|Kubernetes API groups
|Kubernetes nonResourceURLs
|Kubernetes resources
|Kubernetes verbs (permissions)


|``\*``
|
|``\*``
|``\*``

|
|``\*``
|
|``\*``
|===
====

[[access-policy-permissions-amazoneksadminviewpolicy,access-policy-permissions-amazoneksadminviewpolicy.title]]
.AmazonEKSAdminViewPolicy
[%collapsible]
====

This access policy includes permissions that grant an IAM principal access to list/view all resources in a cluster. Note this includes https://kubernetes.io/docs/concepts/configuration/secret/[Kubernetes Secrets.]

*ARN* – `{arn-aws}eks::aws:cluster-access-policy/AmazonEKSAdminViewPolicy`

[cols="1,1,1", options="header"]
|===
|Kubernetes API groups
|Kubernetes resources
|Kubernetes verbs (permissions)


|``\*``
|``\*``
|````get``, `list`, `watch```
|===
====

[[access-policy-permissions-amazonekseditpolicy,access-policy-permissions-amazonekseditpolicy.title]]
.AmazonEKSEditPolicy
[%collapsible]
====

This access policy includes permissions that allow an IAM principal to edit most [.noloc]`Kubernetes` resources.

*ARN* – `{arn-aws}eks::aws:cluster-access-policy/AmazonEKSEditPolicy`

[cols="1,1,1", options="header"]
|===
|Kubernetes API groups
|Kubernetes resources
|Kubernetes verbs (permissions)


|`apps`
|`daemonsets`, `deployments`, `deployments/rollback`, `deployments/scale`, `replicasets`, `replicasets/scale`, `statefulsets`, `statefulsets/scale`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`apps`
|`controllerrevisions`, `daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `replicasets`, `replicasets/scale`, `replicasets/status`, `statefulsets`, `statefulsets/scale`, `statefulsets/status`
|`get`, `list`, `watch`

|`autoscaling`
|`horizontalpodautoscalers`, `horizontalpodautoscalers/status`
|`get`, `list`, `watch`

|`autoscaling`
|`horizontalpodautoscalers`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`batch`
|`cronjobs`, `jobs`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`batch`
|`cronjobs`, `cronjobs/status`, `jobs`, `jobs/status`
|`get`, `list`, `watch`

|`discovery.k8s.io`
|`endpointslices`
|`get`, `list`, `watch`

|`extensions`
|`daemonsets`, `deployments`, `deployments/rollback`, `deployments/scale`, `ingresses`, `networkpolicies`, `replicasets`, `replicasets/scale`, `replicationcontrollers/scale`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`extensions`
|`daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `ingresses`, `ingresses/status`, `networkpolicies`, `replicasets`, `replicasets/scale`, `replicasets/status`, `replicationcontrollers/scale`
|`get`, `list`, `watch`

|`networking.k8s.io`
|`ingresses`, `networkpolicies`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`networking.k8s.io`
|`ingresses`, `ingresses/status`, `networkpolicies`
|`get`, `list`, `watch`

|`policy`
|`poddisruptionbudgets`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|`policy`
|`poddisruptionbudgets`, `poddisruptionbudgets/status`
|`get`, `list`, `watch`

|
|`namespaces`
|`get`, `list`, `watch`

|
|``pods/attach``, `pods/exec`, `pods/portforward`, `pods/proxy`, `secrets`, `services/proxy`
|`get`, `list`, `watch`

|
|`serviceaccounts`
|`impersonate`

|
|`pods`, `pods/attach`, `pods/exec`, `pods/portforward`, `pods/proxy`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|
|`configmaps`, `events`, `persistentvolumeclaims`, `replicationcontrollers`, `replicationcontrollers/scale`, `secrets`, `serviceaccounts`, `services`, `services/proxy`
|`create`, `delete`, `deletecollection`, `patch`, `update`

|
|`configmaps`, `endpoints`, `persistentvolumeclaims`, `persistentvolumeclaims/status`, `pods`, `replicationcontrollers`, `replicationcontrollers/scale`, `serviceaccounts`, `services`, `services/status`
|`get`, `list`, `watch`

|
|`bindings`, `events`, `limitranges`, `namespaces/status`, `pods/log`, `pods/status`, `replicationcontrollers/status`, `resourcequotas`, `resourcequotas/status`
|`get`, `list`, `watch`
|===
====

[[access-policy-permissions-amazoneksviewpolicy.json,access-policy-permissions-amazoneksviewpolicy.json.title]]
.AmazonEKSViewPolicy
[%collapsible]
====

This access policy includes permissions that allow an IAM principal to view most [.noloc]`Kubernetes` resources.

*ARN* – `{arn-aws}eks::aws:cluster-access-policy/AmazonEKSViewPolicy`

[cols="1,1,1", options="header"]
|===
|Kubernetes API groups
|Kubernetes resources
|Kubernetes verbs (permissions)


|`apps`
|`controllerrevisions`, `daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `replicasets`, `replicasets/scale`, `replicasets/status`, `statefulsets`, `statefulsets/scale`, `statefulsets/status`
|`get`, `list`, `watch`

|`autoscaling`
|`horizontalpodautoscalers`, `horizontalpodautoscalers/status`
|`get`, `list`, `watch`

|`batch`
|`cronjobs`, `cronjobs/status`, `jobs`, `jobs/status`
|`get`, `list`, `watch`

|`discovery.k8s.io`
|`endpointslices`
|`get`, `list`, `watch`

|`extensions`
|`daemonsets`, `daemonsets/status`, `deployments`, `deployments/scale`, `deployments/status`, `ingresses`, `ingresses/status`, `networkpolicies`, `replicasets`, `replicasets/scale`, `replicasets/status`, `replicationcontrollers/scale`
|`get`, `list`, `watch`

|`networking.k8s.io`
|`ingresses`, `ingresses/status`, `networkpolicies`
|`get`, `list`, `watch`

|`policy`
|`poddisruptionbudgets`, `poddisruptionbudgets/status`
|`get`, `list`, `watch`

|
|`configmaps`, `endpoints`, `persistentvolumeclaims`, `persistentvolumeclaims/status`, `pods`, `replicationcontrollers`, `replicationcontrollers/scale`, `serviceaccounts`, `services`, `services/status`
|`get`, `list`, `watch`

|
|`bindings`, `events`, `limitranges`, `namespaces/status`, `pods/log`, `pods/status`, `replicationcontrollers/status`, `resourcequotas`, r``esourcequotas/status``
|`get`, `list`, `watch`

|
|`namespaces`
|`get`, `list`, `watch`
|===
====

[[access-policy-updates,access-policy-updates.title]]
=== Access policy updates

View details about updates to access policies, since they were introduced. For automatic alerts about changes to this page, subscribe to the RSS feed in <<doc-history>>.

[cols="1,1,1", options="header"]
|===
|Change
|Description
|Date


|Add `AmazonEKSAdminViewPolicy`
|Add a new policy for expanded view access, including resources like Secrets.
|April 23, 2024

|

Access policies introduced.
|

Amazon EKS introduced access policies.
|May 29, 2023
|===

[.topic]
[[migrating-access-entries,migrating-access-entries.title]]
== Migrating existing `aws-auth ConfigMap` entries to access entries

//GDC: problems with xrefs

If you've added entries to the `aws-auth` `ConfigMap` on your cluster, we recommend that you create access entries for the existing entries in your `aws-auth` `ConfigMap`. After creating the access entries, you can remove the entries from your `ConfigMap`. You can't associate xref:access-policies[access policies,linkend=access-policies] to entries in the `aws-auth` `ConfigMap`. If you want to associate access polices to your IAM principals, create access entries.

[IMPORTANT]
====

Don't remove existing `aws-auth` `ConfigMap` entries that were created by Amazon EKS when you added a <<managed-node-groups,managed node group>> or a <<fargate-profile,Fargate profile>> to your cluster. If you remove entries that Amazon EKS created in the `ConfigMap`, your cluster won't function properly. You can however, remove any entries for <<worker,self-managed>> node groups after you've created access entries for them.

====

* Familiarity with access entries and access policies. For more information, see <<access-entries>> and <<access-policies>>.
* An existing cluster with a platform version that is at or later than the versions listed in the Prerequisites of the <<access-entries,Allowing IAM roles or users access to Kubernetes objects on your Amazon EKS cluster>> topic.
* Version `{eksctl-min-version}` or later of the `eksctl` command line tool installed on your device or {aws} CloudShell. To install or update `eksctl`, see https://eksctl.io/installation[Installation] in the `eksctl` documentation.
* [.noloc]`Kubernetes` permissions to modify the `aws-auth` `ConfigMap` in the `kube-system` namespace.
* An {aws} Identity and Access Management role or user with the following permissions: `CreateAccessEntry` and `ListAccessEntries`. For more information, see  link:service-authorization/latest/reference/list_amazonelastickubernetesservice.html#amazonelastickubernetesservice-actions-as-permissions[Actions defined by Amazon Elastic Kubernetes Service,type="documentation"] in the Service Authorization Reference.
. View the existing entries in your `aws-auth ConfigMap`. Replace [.replaceable]`my-cluster` with the name of your cluster.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
eksctl get iamidentitymapping --cluster my-cluster
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
ARN                                                                                             USERNAME                                GROUPS                                                  ACCOUNT
{arn-aws}iam::111122223333:role/EKS-my-cluster-Admins                                            Admins                                  system:masters
{arn-aws}iam::111122223333:role/EKS-my-cluster-my-namespace-Viewers                              my-namespace-Viewers                    Viewers
{arn-aws}iam::111122223333:role/EKS-my-cluster-self-managed-ng-1                                 system:node:{{EC2PrivateDNSName}}       system:bootstrappers,system:nodes
{arn-aws}iam::111122223333:user/my-user                                                          my-user
{arn-aws}iam::111122223333:role/EKS-my-cluster-fargateprofile1                                   system:node:{{SessionName}}             system:bootstrappers,system:nodes,system:node-proxier
{arn-aws}iam::111122223333:role/EKS-my-cluster-managed-ng                                        system:node:{{EC2PrivateDNSName}}       system:bootstrappers,system:nodes
----
. <<creating-access-entries,Create access entries>> for any of the `ConfigMap` entries that you created returned in the previous output. When creating the access entries, make sure to specify the same values for `ARN`, `USERNAME`, `GROUPS`, and `ACCOUNT` returned in your output. In the example output, you would create access entries for all entries except the last two entries, since those entries were created by Amazon EKS for a Fargate profile and a managed node group. 
. Delete the entries from the `ConfigMap` for any access entries that you created. If you don't delete the entry from the `ConfigMap`, the settings for the access entry for the IAM principal ARN override the `ConfigMap` entry. Replace [.replaceable]`111122223333` with your {aws} account ID and [.replaceable]`EKS-my-cluster-my-namespace-Viewers` with the name of the role in the entry in your `ConfigMap`. If the entry you're removing is for an IAM user, rather than an IAM role, replace `role` with `user` and [.replaceable]`EKS-my-cluster-my-namespace-Viewers` with the user name.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
eksctl delete iamidentitymapping --arn {arn-aws}iam::111122223333:role/EKS-my-cluster-my-namespace-Viewers --cluster my-cluster
----

include::auth-configmap.adoc[leveloffset=+1]


[.topic]
[[authenticate-oidc-identity-provider,authenticate-oidc-identity-provider.title]]
== Grant users access to [.noloc]`Kubernetes` with an external [.noloc]`OIDC` provider

[abstract]
--
Learn how to authenticate users for your Amazon EKS cluster using OpenID Connect (OIDC) identity providers to manage access and permissions with roles, bindings, and RBAC authorization.
--

Amazon EKS supports using [.noloc]`OpenID Connect` ([.noloc]`OIDC`) identity providers as a method to authenticate users to your cluster. [.noloc]`OIDC` identity providers can be used with, or as an alternative to {aws} Identity and Access Management (IAM). For more information about using IAM, see <<grant-k8s-access>>. After configuring authentication to your cluster, you can create [.noloc]`Kubernetes` `roles` and `clusterroles` to assign permissions to the roles, and then bind the roles to the identities using [.noloc]`Kubernetes` `rolebindings` and `clusterrolebindings`. For more information, see https://kubernetes.io/docs/reference/access-authn-authz/rbac/[Using RBAC Authorization] in the [.noloc]`Kubernetes` documentation.



* You can associate one [.noloc]`OIDC` identity provider to your cluster.
* [.noloc]`Kubernetes` doesn't provide an [.noloc]`OIDC` identity provider. You can use an existing public [.noloc]`OIDC` identity provider, or you can run your own identity provider. For a list of certified providers, see https://openid.net/certification/[OpenID Certification] on the OpenID site.
* The issuer URL of the [.noloc]`OIDC` identity provider must be publicly accessible, so that Amazon EKS can discover the signing keys. Amazon EKS doesn't support [.noloc]`OIDC` identity providers with self-signed certificates.
* You can't disable IAM authentication to your cluster, because it's still required for joining nodes to a cluster.
* An Amazon EKS cluster must still be created by an {aws}  link:IAM/latest/UserGuide/id_roles.html#iam-term-principal[IAM principal,type="documentation"], rather than an [.noloc]`OIDC` identity provider user. This is because the cluster creator interacts with the Amazon EKS APIs, rather than the [.noloc]`Kubernetes` APIs.
* [.noloc]`OIDC` identity provider-authenticated users are listed in the cluster's audit log if CloudWatch logs are turned on for the control plane. For more information, see <<enabling-control-plane-log-export>>.
* You can't sign in to the {aws-management-console} with an account from an [.noloc]`OIDC` provider. You can only  <<view-kubernetes-resources,view Kubernetes resources>> in the console by signing into the {aws-management-console} with an {aws} Identity and Access Management account.


[[associate-oidc-identity-provider,associate-oidc-identity-provider.title]]
=== Associate an [.noloc]`OIDC` identity provider

Before you can associate an [.noloc]`OIDC` identity provider with your cluster, you need the following information from your provider:



*Issuer URL*::
The URL of the OIDC identity provider that allows the API server to discover public signing keys for verifying tokens. The URL must begin with `https://` and should correspond to the `iss` claim in the provider's OIDC ID tokens. In accordance with the OIDC standard, path components are allowed but query parameters are not. Typically the URL consists of only a host name, like `https://server.example.org` or `https://example.com`. This URL should point to the level below `.well-known/openid-configuration` and must be publicly accessible over the internet.


*Client ID (also known as _audience_)*::
The ID for the client application that makes authentication requests to the OIDC identity provider.

You can associate an identity provider using `eksctl` or the {aws-management-console}.


[[identity-associate-eksctl,identity-associate-eksctl.title]]
==== Associate an identity provider using eksctl 

. Create a file named [.replaceable]`associate-identity-provider.yaml` with the following contents. Replace the [.replaceable]`example values` with your own. The values in the `identityProviders` section are obtained from your [.noloc]`OIDC` identity provider. Values are only required for the `name`, `type`, `issuerUrl`, and `clientId` settings under `identityProviders`.
+
[source,yaml,subs="verbatim,attributes,quotes"]
----
---
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: my-cluster
  region: your-region-code

identityProviders:
  - name: my-provider
    type: oidc
    issuerUrl: https://example.com
    clientId: kubernetes
    usernameClaim: email
    usernamePrefix: my-username-prefix
    groupsClaim: my-claim
    groupsPrefix: my-groups-prefix
    requiredClaims:
      string: string
    tags:
      env: dev
----
+
IMPORTANT: Don't specify `system:`, or any portion of that string, for `groupsPrefix` or `usernamePrefix`.
. Create the provider.
+
[source,bash,subs="verbatim,attributes,quotes"]
----
eksctl associate identityprovider -f associate-identity-provider.yaml
----
. To use `kubectl` to work with your cluster and [.noloc]`OIDC` identity provider, see https://kubernetes.io/docs/reference/access-authn-authz/authentication/#using-kubectl[Using kubectl] in the [.noloc]`Kubernetes` documentation.

[[identity-associate-console,identity-associate-console.title]]
==== Associate an identity provider using the {aws} Console 
. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. Select your cluster, and then select the *Access* tab.
. In the *[.noloc]`OIDC` Identity Providers* section, select** Associate Identity Provider**.
. On the *Associate [.noloc]`OIDC` Identity Provider* page, enter or select the following options, and then select  *Associate*.
+
** For *Name*, enter a unique name for the provider.
** For *Issuer URL*, enter the URL for your provider. This URL must be accessible over the internet.
** For *Client ID*, enter the [.noloc]`OIDC` identity provider's client ID (also known as  *audience*).
** For *Username claim*, enter the claim to use as the username.
** For *Groups claim*, enter the claim to use as the user's group.
** (Optional) Select *Advanced options*, enter or select the following information.
+
*** *Username prefix* – Enter a prefix to prepend to username claims. The prefix is prepended to username claims to prevent clashes with existing names. If you do not provide a value, and the username is a value other than `email`, the prefix defaults to the value for *Issuer URL*. You can use the value`` -`` to disable all prefixing. Don't specify `system:` or any portion of that string.
*** *Groups prefix* – Enter a prefix to prepend to groups claims. The prefix is prepended to group claims to prevent clashes with existing names (such as`` system: groups``). For example, the value `oidc:` creates group names like `oidc:engineering` and `oidc:infra`. Don't specify `system:` or any portion of that string..
*** *Required claims* – Select  *Add claim* and enter one or more key value pairs that describe required claims in the client ID token. The pairs describe required claims in the ID Token. If set, each claim is verified to be present in the ID token with a matching value.
.. To use `kubectl` to work with your cluster and [.noloc]`OIDC` identity provider, see https://kubernetes.io/docs/reference/access-authn-authz/authentication/#using-kubectl[Using kubectl] in the [.noloc]`Kubernetes` documentation.


[[oidc-identity-provider-iam-policy,oidc-identity-provider-iam-policy.title]]
=== Example IAM policy

If you want to prevent an [.noloc]`OIDC` identity provider from being associated with a cluster, create and associate the following IAM policy to the IAM accounts of your Amazon EKS administrators. For more information, see   link:IAM/latest/UserGuide/access_policies_create.html[Creating IAM policies,type="documentation"] and  link:IAM/latest/UserGuide/access_policies_manage-attach-detach.html#add-policies-console[Adding IAM identity permissions,type="documentation"] in the IAM User Guide and  link:service-authorization/latest/reference/list_amazonelasticcontainerserviceforkubernetes.html[Actions, resources, and condition keys for Amazon Elastic Kubernetes Service,type="documentation"] in the Service Authorization Reference.

[source,json,subs="verbatim,attributes,quotes"]
----
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "denyOIDC",
            "Effect": "Deny",
            "Action": [
                "eks:AssociateIdentityProviderConfig"
            ],
            "Resource": "{arn-aws}eks:us-west-2.amazonaws.com:111122223333:cluster/*"

        },
        {
            "Sid": "eksAdmin",
            "Effect": "Allow",
            "Action": [
                "eks:*"
            ],
            "Resource": "*"
        }
    ]
}
----

The following example policy allows [.noloc]`OIDC` identity provider association if the `clientID` is `kubernetes` and the `issuerUrl` is `https://cognito-idp.us-west-2amazonaws.com/*`.

[source,json,subs="verbatim,attributes,quotes"]
----
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowCognitoOnly",
            "Effect": "Deny",
            "Action": "eks:AssociateIdentityProviderConfig",
            "Resource": "{arn-aws}eks:us-west-2:111122223333:cluster/my-instance",
            "Condition": {
                "StringNotLikeIfExists": {
                    "eks:issuerUrl": "https://cognito-idp.us-west-2.amazonaws.com/*"
                }
            }
        },
        {
            "Sid": "DenyOtherClients",
            "Effect": "Deny",
            "Action": "eks:AssociateIdentityProviderConfig",
            "Resource": "{arn-aws}eks:us-west-2:111122223333:cluster/my-instance",
            "Condition": {
                "StringNotEquals": {
                    "eks:clientId": "kubernetes"
                }
            }
        },
        {
            "Sid": "AllowOthers",
            "Effect": "Allow",
            "Action": "eks:*",
            "Resource": "*"
        }
    ]
}
----


[[partner-validated-identity-providers,partner-validated-identity-providers.title]]
=== Partner validated [.noloc]`OIDC` identity providers

Amazon EKS maintains relationships with a network of partners that offer support for compatible [.noloc]`OIDC` identity providers. Refer to the following partners' documentation for details on how to integrate the identity provider with Amazon EKS.

[cols="1,1,1", options="header"]
|===
|Partner
|Product
|Documentation


|

PingIdentity
|

https://docs.pingidentity.com/r/en-us/pingoneforenterprise/p14e_landing[PingOne for Enterprise]
|

https://docs.pingidentity.com/r/en-us/solution-guides/htg_config_oidc_authn_aws_eks_custers[Installation instructions]
|===

Amazon EKS aims to give you a wide selection of options to cover all use cases. If you develop a commercially supported [.noloc]`OIDC` compatible identity provider that is not listed here, then contact our partner team at  link:mailto:aws-container-partners@amazon.com[aws-container-partners@amazon.com] for more information.

[.topic]
[[disassociate-oidc-identity-provider,disassociate-oidc-identity-provider.title]]
== Disassociate an [.noloc]`OIDC` identity provider from your cluster

If you disassociate an [.noloc]`OIDC` identity provider from your cluster, users included in the provider can no longer access the cluster. However, you can still access the cluster with   link:IAM/latest/UserGuide/id_roles.html#iam-term-principal[IAM principals,type="documentation"].

. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
. In the *[.noloc]`OIDC` Identity Providers* section, select  *Disassociate*, enter the identity provider name, and then select `Disassociate`.
