Severity,Short Name,Category,Details
Condition,NeuronSRAMUncorrectableError,neuron,
Condition,NeuronNCUncorrectableError,neuron,
Condition,NeuronHBMUncorrectableError,neuron,
Condition,NeuronDMAError,neuron,
Condition,NvidiaXID%dError,nvidia,XID codes from Node Auto Repair - Unhealthy GPUs
Event,NvidiaXID%dWarning,nvidia,XID codes not from Node Auto Repair - Unhealthy GPUs
Condition,NvidiaDoubleBitError,nvidia,
Condition,NvidiaNVLinkError,nvidia,
Event,NvidiaPageRetirement,nvidia,
Condition,MissingLoopbackInterface,networking,"The loopback interface is missing from this instance. Without it, many services which depend on local connectivity (e.g. VPC CNI) will fail. This can be caused by PID recycling in docker or containerd, with the containerd issue https://github.com/containerd/containerd/issues/5630 tracking the problem."
Condition,InterfaceNotUp,networking,"This interface appears to not be up. If this is an interface that was launched by the VPC CNI or one that is in use by a customer, its status will cause network issues."
Condition,InterfaceNotRunning,networking,"This interface appears to not be running. If this is an interface that was launched by the VPC CNI or one that is in use by a customer, its status will cause network issues."
Event,KubeProxyNotReady,networking,kube-proxy fails to watch and/or list resources
Condition,IPAMDNotReady,networking,IPAMD fails to connect to the api server
Event,IPAMDRepeatedlyRestart,networking,multiple restarts in ipamd.log
Event,IPAMDNoIPs,networking,"IPAM-D is out of IP addresses,"
Event,BandwidthInExceeded,networking,"Rx Packets Queued/Dropped, Packets have been queued and/or dropped because the inbound aggregate bandwidth exceeded the maximum for the instance."
Event,BandwidthOutExceeded,networking,"Bandwidth Out Allowance Exceeded, Packets have been queued and/or dropped because the outbound aggregate bandwidth exceeded the maximum for the instance."
Event,PPSExceeded,networking,"Tx Packets Queued/Dropped, Packets have been queued and/or dropped because the bidirectional PPS exceeded the maximum for the instance."
Event,ConntrackExceeded,networking,"Maximum Connections Exceeded, Connection tracking exceeded the maximum for the instance and new connections could not be established. This can result in packet loss for traffic to or from the instance."
Event,LinkLocalExceeded,networking,"LinkLocal Packets Dropped, Packets dropped because the PPS of the traffic to local proxy services exceeded the maximum for the network interface. This impacts traffic to the DNS service, the Instance Metadata Service, and the Amazon Time Sync Service."
Event,UnexpectedRejectRule,networking,"Unexpected Reject Rule, An unexpected REJECT or DROP rule was found in the iptables. This may have been installed by some third-party software and could be blocking traffic that we expect to not be blocked. This might not be a problem, but if the node is experiencing network problems and this rule matches the traffic that is failing, it is likely the cause."
Event,MissingDefaultRoutes,networking,"Missing default route rules, Missing default route rules for the following tables"
Event,MissingIPRouteRules,networking,"Missing pod IP route rules, Missing route rules for the following pod IPs from the route table"
Event,NetworkSysctl,networking,"Network Sysctl Setting Incorrect, This network sysctl setting is potentially incorrect."
Condition,NoIPAMDFound IPAMDNotRunning,networking,"IPAMDNotRunning, The aws-k8s-agent process was not found to be running. If this node uses the {aws} VPC CNI, this should have been found. If the {aws} VPC CNI is not used, this is not an error."
,,,
Event,RapidCron,kernel,"Rapid Cron Job, A cron job is running faster than every 5 minutes on this node. This may not be an issue, but if the cron job consumes a non-trivial amount of resources it can lead to varying performance impacts."
Event,LargeEnvironment,kernel,"Large Environment, The number of environment variables for this process is larger than expected. This can be caused by having many services in a cluster with the Pod setting of enableServiceLinks set to true (the default. This may cause performance issues, see https://github.com/kubernetes/kubernetes/issues/121787 for more information.)"
Event,CPUThrottling,kernel,"CPU Throttling, A process had it's execution throttled by CPU limits within cgroups. If this process is part of a container, it may indicate that the containers CPU request should be increased. Throttling may or may not be an issue, it depends on the workloads and if throttling is expected."
Event,ConntrackExceededKernel,kernel,"Maximum Connections Exceeded (Kernel, Connection tracking exceeded the maximum for the kernel and new connections could not be established. This can result in packet loss.)"
Event,ApproachingMaxOpenFiles,kernel,"Approaching Exhaustion of max open file descriptors, The number of open files is approaching the maximum number of possible open files given the current kernel settings. Once this limit is reached, opening new files will fail."
Event,ApproachingKernelPidMax,kernel,"Approaching Exhaustion of kernel.pid_max, The number of processes is approaching the maximum number of PIDs that are available per the current kernel.pid_max setting. Once this limit is reached, no more processes can be launched."
Event,ExcessiveZombieProcesses,kernel,"Excessive Zombie Processes, Zombie processes are those that can't be fully reclaimed as their parent process hasn't waited on it. The process is no longer running and can't be killed. If there are a a large number of zombie processe it indicates that something related to an application has gone wrong. If this continues to occur, the maximum number of processes on the system may be reached."
Event,SoftLockup,kernel,"Soft Lockup, where the CPU stalls for a given amount of time"
Event,KernelBug,kernel,"Kernel Bug, A kernel bug was detected and reported by the Linux kernel itself. In some circumstances this may not indicate an actual kernel bug and can instead be caused expected nodes with high CPU or memory usage which may lead to events taking longer than exepcted to process."
Event,AppBlocked,kernel,"Application Blocked with Uninterruptible Sleep, The task has been blocked for a long period of time from scheduling. This is usually caused by being blocked on I/O."
Event,AppCrash,kernel,"Application Crash, An application on the node has crashed."
Condition,ForkFailedOutOfPID,kernel,"fork/exec Failure due to PID Exhaustion or OOM, A fork or exec call has failed due to the system being out of process IDs or memory.The PID limit can be raised on the machine if it truly needs to run many processes (e.g. 32k+ but more likely the failure is due to zombie processes. If the machine doesn't have many processes running, this may also be caused by simply being out of physical memory. This will usually be accompanied with OOM kills.')"
,,,
Condition,PodStuckTerminating,runtime,"Pod stuck terminating, A pod is/was stuck terminating for an excessive amount of time. There is a known issue fixed in 1.27+, https://github.com/kubernetes/kubernetes/pull/113145, where CRI errors in the terminating phase can prevent the pod state machine from progressing. This has been noticed when under excessive I/O pressure. Restarting kubelet will result in cleaning up stuck pods. Upgrade to 1.27+ or reduce I/O pressure."
Event,ContainerRuntimeFailed,runtime,"Container Runtime Failed, The container runtime has failed to create a container. If this is repeatedly occurring, its likely related to any reported issues."
Event,KubeletFailed,runtime,Kublet entered a failed state.
Event,KubeletRepeatedlyRestart,runtime,"Kubelet has restated multiple times, Multiple Kubelet restarts can affect general functioning of Worker Node. If there is no finding for E0016 then this may be due some script executed on worker node."
Event,ServiceFailedToStart,runtime,A systemd unit failed to start
Event,ReadinessProbeFailed,runtime,"Readiness Probe Failed, A readiness probe failure was detected. If this repeatedly occurs, the relevant containers will be restarted by the kubelet. This may indicate an issue with application code within the container or a readiness timeout value which is too small."
Event,LivenessProbeFailed,runtime,"Liveness Probe Failed, A liveness probe failure was detected. If this repeatedly occurs, the relevant containers will be restarted by the kubelet. This may indicate an issue with application code within the container or a readiness timeout value which is too small."
Event,KubeletDiskUsageSlow,storage,"Kubelet Disk Usage Slow, Kubelet is reporting slow disk usage while trying to access the filesystem, typically for a pod. This may indicate that the disk I/O provisioned is not sufficient or that there is something wrong with the filesystem (e.g. an inability to access a network filesystem.)"
,,,good indicator for EBS throttling
Event,IODelays,storage,"I/O Delay, A process had it's disk I/O delayed. If excessive, this can indicate that increased I/O provisioning may be warranted."
Condition,XFSSmallAverageClusterSize,storage,"Small XFS Average Cluster Size, The XFS Average Cluster size is small which can indicate free space being excessively fragmented. This can lead to the inability to write files to disk, even though it appears there are enough inodes/free space available. With XFS, inodes are dynamically allocated and excessive free space fragmentation can prevent their allocation if there are not enough contiguous blocks free for inodes to be allocated. This prevents new files from being created."
Event,EtcHostsMountFailed,storage,Mounting of the kubelet generated /etc/hosts failed. This has been caused by userdata remounting /var/lib/kubelet/pods while kubelet/container are running.
