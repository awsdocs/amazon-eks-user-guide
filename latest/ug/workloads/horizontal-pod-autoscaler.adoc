//!!NODE_ROOT <section>
include::../attributes.txt[]

[.topic]
[[horizontal-pod-autoscaler,horizontal-pod-autoscaler.title]]
= Scale pod deployments with [.noloc]`Horizontal Pod Autoscaler`
:info_doctype: section
:info_title: Scale pod deployments with Horizontal Pod Autoscaler
:info_titleabbrev: Horizontal Pod Autoscaler
:info_abstract: Learn how to use the Kubernetes Horizontal Pod Autoscaler to automatically scale your Amazon EKS deployments based on CPU utilization for efficient resource management.

[abstract]
--
Learn how to use the Kubernetes Horizontal Pod Autoscaler to automatically scale your Amazon EKS deployments based on CPU utilization for efficient resource management.
--

The [.noloc]`Kubernetes` https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/[Horizontal Pod Autoscaler] automatically scales the number of [.noloc]`Pods` in a deployment, replication controller, or replica set based on that resource's CPU utilization. This can help your applications scale out to meet increased demand or scale in when resources are not needed, thus freeing up your nodes for other applications. When you set a target CPU utilization percentage, the Horizontal Pod Autoscaler scales your application in or out to try to meet that target.

The [.noloc]`Horizontal Pod Autoscaler` is a standard API resource in [.noloc]`Kubernetes` that simply requires that a metrics source (such as the [.noloc]`Kubernetes` metrics server) is installed on your Amazon EKS cluster to work. You do not need to deploy or install the [.noloc]`Horizontal Pod Autoscaler` on your cluster to begin scaling your applications. For more information, see https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/[Horizontal Pod Autoscaler] in the [.noloc]`Kubernetes` documentation.

Use this topic to prepare the [.noloc]`Horizontal Pod Autoscaler` for your Amazon EKS cluster and to verify that it is working with a sample application.

[NOTE]
====

This topic is based on the https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/[Horizontal Pod autoscaler walkthrough] in the [.noloc]`Kubernetes` documentation.

====

* You have an existing Amazon EKS cluster. If you don't, see <<getting-started>>.
* You have the [.noloc]`Kubernetes` Metrics Server installed. For more information, see <<metrics-server>>.
* You are using a `kubectl` client that is <<eks-configure-kubectl,configured to communicate with your Amazon EKS cluster>>.


[[hpa-sample-app,hpa-sample-app.title]]
== Run a Horizontal Pod Autoscaler test application

In this section, you deploy a sample application to verify that the Horizontal Pod Autoscaler is working.

[NOTE]
====

This example is based on the https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/[Horizontal Pod autoscaler walkthrough] in the [.noloc]`Kubernetes` documentation.

====
. Deploy a simple Apache web server application with the following command.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
----
+
This Apache web server [.noloc]`Pod` is given a 500 millicpu CPU limit and it is serving on port 80.
. Create a Horizontal Pod Autoscaler resource for the `php-apache` deployment.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
----
+
This command creates an autoscaler that targets 50 percent CPU utilization for the deployment, with a minimum of one [.noloc]`Pod` and a maximum of ten [.noloc]`Pods`. When the average CPU load is lower than 50 percent, the autoscaler tries to reduce the number of [.noloc]`Pods` in the deployment, to a minimum of one. When the load is greater than 50 percent, the autoscaler tries to increase the number of [.noloc]`Pods` in the deployment, up to a maximum of ten. For more information, see https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#how-does-a-horizontalpodautoscaler-work[How does a HorizontalPodAutoscaler work?] in the [.noloc]`Kubernetes` documentation.
. Describe the autoscaler with the following command to view its details.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl get hpa
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes"]
----
NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache   0%/50%    1         10        1          51s
----
+
As you can see, the current CPU load is `0%`, because there's no load on the server yet. The [.noloc]`Pod` count is already at its lowest boundary (one), so it cannot scale in.
. [[hpa-create-load]]Create a load for the web server by running a container.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl run -i \
    --tty load-generator \
    --rm --image=busybox \
    --restart=Never \
    -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
----
. To watch the deployment scale out, periodically run the following command in a separate terminal from the terminal that you ran the previous step in.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl get hpa php-apache
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes"]
----
NAME         REFERENCE               TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache   250%/50%   1         10        5          4m44s
----
+
It may take over a minute for the replica count to increase. As long as actual CPU percentage is higher than the target percentage, then the replica count increases, up to 10. In this case, it's `250%`, so the number of `REPLICAS` continues to increase.
+
NOTE: It may take a few minutes before you see the replica count reach its maximum. If only 6 replicas, for example, are necessary for the CPU load to remain at or under 50%, then the load won't scale beyond 6 replicas.
. Stop the load. In the terminal window you're generating the load in, stop the load by holding down the `Ctrl+C` keys. You can watch the replicas scale back to 1 by running the following command again in the terminal that you're watching the scaling in.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl get hpa
----
+
An example output is as follows.
+
[source,bash,subs="verbatim,attributes"]
----
NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
php-apache   Deployment/php-apache   0%/50%    1         10        1          25m
----
+
NOTE: The default timeframe for scaling back down is five minutes, so it will take some time before you see the replica count reach 1 again, even when the current CPU percentage is 0 percent. The timeframe is modifiable. For more information, see https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/[Horizontal Pod Autoscaler] in the [.noloc]`Kubernetes` documentation.
. When you are done experimenting with your sample application, delete the `php-apache` resources.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl delete deployment.apps/php-apache service/php-apache horizontalpodautoscaler.autoscaling/php-apache
----
