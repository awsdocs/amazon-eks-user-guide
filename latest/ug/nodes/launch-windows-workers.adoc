//!!NODE_ROOT <section>
include::../attributes.txt[]
[.topic]
[[launch-windows-workers,launch-windows-workers.title]]
= Create self-managed [.noloc]`Microsoft Windows` nodes
:info_titleabbrev: Windows

[abstract]
--
This topic describes how to launch Auto Scaling groups of [.noloc]`Windows` nodes that register with your Amazon EKS cluster.
--

This topic describes how to launch Auto Scaling groups of [.noloc]`Windows` nodes that register with your Amazon EKS cluster. After the nodes join the cluster, you can deploy [.noloc]`Kubernetes` applications to them.

[IMPORTANT]
====


* Amazon EKS nodes are standard Amazon EC2 instances, and you are billed for them based on normal Amazon EC2 instance prices. For more information, see link:ec2/pricing/[Amazon EC2 pricing,type="marketing"].
* You can launch Windows nodes in Amazon EKS extended clusters on {aws} Outposts, but you can't launch them in local clusters on {aws} Outposts. For more information, see <<eks-outposts>>.

====

Enable [.noloc]`Windows` support for your cluster. We recommend that you review important considerations before you launch a [.noloc]`Windows` node group. For more information, see <<enable-windows-support>>. 

You can launch self-managed [.noloc]`Windows` nodes with either of the following:

* <<eksctl_create_windows_nodes>>
* <<console_create_windows_nodes>>

== `eksctl` [[eksctl_create_windows_nodes]]

*Launch self-managed Windows nodes using `eksctl`*`

This procedure requires that you have installed `eksctl`, and that your `eksctl` version is at least `{eksctl-min-version}`. You can check your version with the following command.

[source,bash,subs="verbatim,attributes"]
----
eksctl version
----

For instructions on how to install or upgrade `eksctl`, see https://eksctl.io/installation[Installation] in the `eksctl` documentation.

[NOTE]
====
This procedure only works for clusters that were created with `eksctl`.
====

. (Optional) If the *AmazonEKS_CNI_Policy* managed IAM policy (if you have an `IPv4` cluster) or the [.replaceable]`AmazonEKS_CNI_IPv6_Policy` (that you <<cni-iam-role-create-ipv6-policy,created yourself>> if you have an `IPv6` cluster) is attached to your <<create-node-role,Amazon EKS node IAM role>>, we recommend assigning it to an IAM role that you associate to the [.noloc]`Kubernetes` `aws-node` service account instead. For more information, see <<cni-iam-role>>.
. This procedure assumes that you have an existing cluster. If you don't already have an Amazon EKS cluster and an Amazon Linux node group to add a [.noloc]`Windows` node group to, we recommend that you follow  <<getting-started-eksctl>>. This guide provides a complete walkthrough for how to create an Amazon EKS cluster with Amazon Linux nodes.
+
Create your node group with the following command. Replace [.replaceable]`region-code` with the {aws} Region that your cluster is in. Replace [.replaceable]`my-cluster` with your cluster name. The name can contain only alphanumeric characters (case-sensitive) and hyphens. It must start with an alphanumeric character and can't be longer than 100 characters. The name must be unique within the {aws} Region and {aws} account that you're creating the cluster in. Replace [.replaceable]`ng-windows` with a name for your node group. The node group name can't be longer than 63 characters. It must start with letter or digit, but can also include hyphens and underscores for the remaining characters. For [.noloc]`Kubernetes` version `1.24` or later, you can replace [.replaceable]`2019` with `2022` to use [.noloc]`Windows` Server 2022. Replace the rest of the [.replaceable]`example values` with your own values.
+
IMPORTANT: To deploy a node group to {aws} Outposts, {aws} Wavelength, or {aws} Local Zone subnets, don't pass the {aws} Outposts, Wavelength, or Local Zone subnets when you create the cluster. Create the node group with a config file, specifying the {aws} Outposts, Wavelength, or Local Zone subnets. For more information, see https://eksctl.io/usage/nodegroups/#creating-a-nodegroup-from-a-config-file[Create a nodegroup from a config file] and https://eksctl.io/usage/schema/[Config file schema] in the `eksctl` documentation.
+
[source,bash,subs="verbatim,attributes"]
----
eksctl create nodegroup \
    --region region-code \
    --cluster my-cluster \
    --name ng-windows \
    --node-type t2.large \
    --nodes 3 \
    --nodes-min 1 \
    --nodes-max 4 \
    --managed=false \
    --node-ami-family WindowsServer2019FullContainer
----
+
[NOTE]
==== 
** If nodes fail to join the cluster, see <<worker-node-fail>> in the Troubleshooting guide.
** To see the available options for `eksctl` commands, enter the following command.
+
[source,bash,subs="verbatim,attributes"]
----
eksctl command -help
----
====
+
An example output is as follows. Several lines are output while the nodes are created. One of the last lines of output is the following example line.
+
[source,bash,subs="verbatim,attributes"]
----
[âœ”]  created 1 nodegroup(s) in cluster "my-cluster"
----
. (Optional) Deploy a <<sample-deployment,sample application>> to test your cluster and [.noloc]`Windows` nodes.
. We recommend blocking [.noloc]`Pod` access to IMDS if the following conditions are true:
+
** You plan to assign IAM roles to all of your [.noloc]`Kubernetes` service accounts so that [.noloc]`Pods` only have the minimum permissions that they need.
** No [.noloc]`Pods` in the cluster require access to the Amazon EC2 instance metadata service (IMDS) for other reasons, such as retrieving the current {aws} Region.

+
For more information, see https://aws.github.io/aws-eks-best-practices/security/docs/iam/#restrict-access-to-the-instance-profile-assigned-to-the-worker-node[Restrict access to the instance profile assigned to the worker node].

== {aws-management-console} [[console_create_windows_nodes]]

*Prerequisites*

** An existing Amazon EKS cluster and a [.noloc]`Linux` node group. If you don't have these resources, we recommend that you create them using one of our guides in <<getting-started>>. These guides describe how to create an Amazon EKS cluster with [.noloc]`Linux` nodes.
** An existing VPC and security group that meet the requirements for an Amazon EKS cluster. For more information, see <<network-reqs>> and <<sec-group-reqs>>. The guides in <<getting-started>> create a VPC that meets the requirements. Alternatively, you can also follow <<creating-a-vpc,Create an Amazon VPC for your Amazon EKS cluster>> to create one manually.
** An existing Amazon EKS cluster that uses a VPC and security group that meets the requirements of an Amazon EKS cluster. For more information, see <<create-cluster>>. If you have subnets in the {aws} Region where you have {aws} Outposts, {aws} Wavelength, or {aws} Local Zones enabled, those subnets must not have been passed in when you created the cluster.

*Step 1: Launch self-managed Windows nodes using the {aws-management-console}*

. Wait for your cluster status to show as `ACTIVE`. If you launch your nodes before the cluster is active, the nodes fail to register with the cluster and you need to relaunch them.
. Open the link:cloudformation/[{aws} CloudFormation console,type="console"]
. Choose *Create stack*.
. For *Specify template*, select  *Amazon S3 URL*.
. Copy the following URL and paste it into *Amazon S3 URL*.
+
[source,none,subs="verbatim,attributes"]
----
https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2023-02-09/amazon-eks-windows-nodegroup.yaml
----
. Select *Next* twice.
. On the *Quick create stack* page, enter the following parameters accordingly:
+
** *Stack name*: Choose a stack name for your {aws} CloudFormation stack. For example, you can call it [.replaceable]`my-cluster`-nodes````.
** *ClusterName*: Enter the name that you used when you created your Amazon EKS cluster.
+
[IMPORTANT]
====
This name must exactly match the name that you used in <<eks-create-cluster,Step 1: Create your Amazon EKS cluster>>. Otherwise, your nodes can't join the cluster.
====
** *ClusterControlPlaneSecurityGroup*: Choose the security group from the {aws} CloudFormation output that you generated when you created your  <<creating-a-vpc,VPC>>.
The following steps show one method to retrieve the applicable group.
+
.. Open the link:eks/home#/clusters[Amazon EKS console,type="console"].
.. Choose the name of the cluster.
.. Choose the *Networking* tab.
.. Use the *Additional security groups* value as a reference when selecting from the  *ClusterControlPlaneSecurityGroup* dropdown list.
** *NodeGroupName*: Enter a name for your node group. This name can be used later to identify the Auto Scaling node group that's created for your nodes. The node group name can't be longer than 63 characters. It must start with letter or digit, but can also include hyphens and underscores for the remaining characters.
** *NodeAutoScalingGroupMinSize*: Enter the minimum number of nodes that your node Auto Scaling group can scale in to.
** *NodeAutoScalingGroupDesiredCapacity*: Enter the desired number of nodes to scale to when your stack is created.
** *NodeAutoScalingGroupMaxSize*: Enter the maximum number of nodes that your node Auto Scaling group can scale out to.
** *NodeInstanceType*: Choose an instance type for your nodes. For more information, see <<choosing-instance-type>>.
+
NOTE: The supported instance types for the latest version of the https://github.com/aws/amazon-vpc-cni-k8s[Amazon VPC CNI plugin for Kubernetes] are listed in https://github.com/aws/amazon-vpc-cni-k8s/blob/master/pkg/vpc/vpc_ip_resource_limit.go[vpc_ip_resource_limit.go] on [.noloc]`GitHub`. You might need to update your CNI version to use the latest supported instance types. For more information, see <<managing-vpc-cni>>.
** *NodeImageIdSSMParam*: Pre-populated with the Amazon EC2 Systems Manager parameter of the current recommended Amazon EKS optimized [.noloc]`Windows` Core AMI ID. To use the full version of [.noloc]`Windows`, replace [.replaceable]`Core` with `Full`.
** *NodeImageId*: (Optional) If you're using your own custom AMI (instead of the Amazon EKS optimized AMI), enter a node AMI ID for your {aws} Region. If you specify a value for this field, it overrides any values in the  *NodeImageIdSSMParam* field.
** *NodeVolumeSize*: Specify a root volume size for your nodes, in GiB.
** *KeyName*: Enter the name of an Amazon EC2 SSH key pair that you can use to connect using SSH into your nodes with after they launch. If you don't already have an Amazon EC2 key pair, you can create one in the {aws-management-console}. For more information, see link:AWSEC2/latest/WindowsGuide/ec2-key-pairs.html[Amazon EC2 key pairs,type="documentation"] in the _Amazon EC2 User Guide_.
+
NOTE: If you don't provide a key pair here, the {aws} CloudFormation stack fails to be created.
** *BootstrapArguments*: Specify any optional arguments to pass to the node bootstrap script, such as extra `kubelet` arguments using `-KubeletExtraArgs`. 
** *DisableIMDSv1*: By default, each node supports the Instance Metadata Service Version 1 (IMDSv1) and IMDSv2. You can disable IMDSv1. To prevent future nodes and [.noloc]`Pods` in the node group from using MDSv1, set  *DisableIMDSv1* to  *true*. For more information about IMDS, see link:AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html[Configuring the instance metadata service,type="documentation"].
** *VpcId*: Select the ID for the  <<creating-a-vpc,VPC>> that you created.
** *NodeSecurityGroups*: Select the security group that was created for your [.noloc]`Linux` node group when you created your  <<creating-a-vpc,VPC>>. If your [.noloc]`Linux` nodes have more than one security group attached to them, specify all of them. This for, for example, if the [.noloc]`Linux` node group was created with `eksctl`.
** *Subnets*: Choose the subnets that you created. If you created your VPC using the steps in  <<creating-a-vpc,Create an Amazon VPC for your Amazon EKS cluster>>, then specify only the private subnets within the VPC for your nodes to launch into.
+
[IMPORTANT]
==== 
*** If any of the subnets are public subnets, then they must have the automatic public IP address assignment setting enabled. If the setting isn't enabled for the public subnet, then any nodes that you deploy to that public subnet won't be assigned a public IP address and won't be able to communicate with the cluster or other {aws} services. If the subnet was deployed before March 26, 2020 using either of the <<creating-a-vpc,Amazon EKS {aws} CloudFormation VPC templates>>, or by using `eksctl`, then automatic public IP address assignment is disabled for public subnets. For information about how to enable public IP address assignment for a subnet, see  link:vpc/latest/userguide/vpc-ip-addressing.html#subnet-public-ip[Modifying the public IPv4 addressing attribute for your subnet,type="documentation"]. If the node is deployed to a private subnet, then it's able to communicate with the cluster and other {aws} services through a NAT gateway.
*** If the subnets don't have internet access, then make sure that you're aware of the considerations and extra steps in <<private-clusters,Deploy private clusters with limited internet access>>.
*** If you select {aws} Outposts, Wavelength, or Local Zone subnets, then the subnets must not have been passed in when you created the cluster.
====
. Acknowledge that the stack might create IAM resources, and then choose *Create stack*.
. When your stack has finished creating, select it in the console and choose *Outputs*.
. Record the *NodeInstanceRole* for the node group that was created. You need this when you configure your Amazon EKS [.noloc]`Windows` nodes.

*Step 2: Enable nodes to join your cluster*

. Check to see if you already have an `aws-auth` `ConfigMap`.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl describe configmap -n kube-system aws-auth
----
. If you are shown an `aws-auth` `ConfigMap`, then update it as needed.
+
.. Open the `ConfigMap` for editing.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl edit -n kube-system configmap/aws-auth
----
.. Add new `mapRoles` entries as needed. Set the `rolearn` values to the *NodeInstanceRole* values that you recorded in the previous procedures.
+
[source,yaml,subs="verbatim,attributes"]
----
[...]
data:
  mapRoles: |
- rolearn: <ARN of linux instance role (not instance profile)>
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
    - rolearn: <ARN of windows instance role (not instance profile)>
      username: system:node:{{EC2PrivateDNSName}}
      groups:
        - system:bootstrappers
        - system:nodes
        - eks:kube-proxy-windows
[...]
----
.. Save the file and exit your text editor.
. If you received an error stating "``Error from server (NotFound): configmaps "aws-auth" not found``, then apply the stock `ConfigMap`.
+
.. Download the configuration map.
+
[source,bash,subs="verbatim,attributes"]
----
curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/cloudformation/2020-10-29/aws-auth-cm-windows.yaml
----
.. In the ``aws-auth-cm-windows.yaml`` file, set the `rolearn` values to the applicable *NodeInstanceRole* values that you recorded in the previous procedures. You can do this with a text editor, or by replacing the [.replaceable]`example values` and running the following command:
+
[source,bash,subs="verbatim,attributes"]
----
sed -i.bak -e 's|<ARN of linux instance role (not instance profile)>|my-node-linux-instance-role|' \
    -e 's|<ARN of windows instance role (not instance profile)>|my-node-windows-instance-role|' aws-auth-cm-windows.yaml
----
+
[IMPORTANT]
====
*** Don't modify any other lines in this file.
*** Don't use the same IAM role for both [.noloc]`Windows` and [.noloc]`Linux` nodes.
====
.. Apply the configuration. This command might take a few minutes to finish.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl apply -f aws-auth-cm-windows.yaml
----
. Watch the status of your nodes and wait for them to reach the `Ready` status.
+
[source,bash,subs="verbatim,attributes"]
----
kubectl get nodes --watch
----
+
Enter `Ctrl`+``C`` to return to a shell prompt.
+
NOTE: If you receive any authorization or resource type errors, see <<unauthorized>> in the troubleshooting topic.
+
If nodes fail to join the cluster, then see <<worker-node-fail>> in the Troubleshooting chapter.

*Step 3: Additional actions*

. (Optional) Deploy a <<sample-deployment,sample application>> to test your cluster and [.noloc]`Windows` nodes.
. (Optional) If the *AmazonEKS_CNI_Policy* managed IAM policy (if you have an `IPv4` cluster) or the [.replaceable]`AmazonEKS_CNI_IPv6_Policy` (that you <<cni-iam-role-create-ipv6-policy,created yourself>> if you have an `IPv6` cluster) is attached to your <<create-node-role,Amazon EKS node IAM role>>, we recommend assigning it to an IAM role that you associate to the [.noloc]`Kubernetes` `aws-node` service account instead. For more information, see <<cni-iam-role>>.
. We recommend blocking [.noloc]`Pod` access to IMDS if the following conditions are true:
+
** You plan to assign IAM roles to all of your [.noloc]`Kubernetes` service accounts so that [.noloc]`Pods` only have the minimum permissions that they need.
** No [.noloc]`Pods` in the cluster require access to the Amazon EC2 instance metadata service (IMDS) for other reasons, such as retrieving the current {aws} Region.

+
For more information, see https://aws.github.io/aws-eks-best-practices/security/docs/iam/#restrict-access-to-the-instance-profile-assigned-to-the-worker-node[Restrict access to the instance profile assigned to the worker node].


