//!!NODE_ROOT <section>
[.topic]
[[managed-node-groups,managed-node-groups.title]]
= Simplify node lifecycle with managed node groups
:info_doctype: section
:info_title: Simplify node lifecycle with managed node groups
:info_titleabbrev: Managed node groups
:keywords: managed node group, MNG
:info_abstract: Amazon EKS managed node groups automate the provisioning and lifecycle management of \
                nodes (Amazon EC2 instances) for Amazon EKS Kubernetes clusters.

include::../attributes.txt[]

include::create-managed-node-group.adoc[leveloffset=+1]

include::capacity-blocks-mng.adoc[leveloffset=+1]

include::update-managed-node-group.adoc[leveloffset=+1]

include::managed-node-update-behavior.adoc[leveloffset=+1]

include::node-taints-managed-node-groups.adoc[leveloffset=+1]

include::launch-templates.adoc[leveloffset=+1]

include::delete-managed-node-group.adoc[leveloffset=+1]

[abstract]
--
Amazon EKS managed node groups automate the provisioning and lifecycle management of nodes (Amazon EC2 instances) for Amazon EKS [.noloc]`Kubernetes` clusters.
--

Amazon EKS managed node groups automate the provisioning and lifecycle management of nodes (Amazon EC2 instances) for Amazon EKS [.noloc]`Kubernetes` clusters.

With Amazon EKS managed node groups, you don't need to separately provision or register the Amazon EC2 instances that provide compute capacity to run your [.noloc]`Kubernetes` applications. You can create, automatically update, or terminate nodes for your cluster with a single operation. Node updates and terminations automatically drain nodes to ensure that your applications stay available.

Every managed node is provisioned as part of an Amazon EC2 Auto Scaling group that's managed for you by Amazon EKS. Every resource including the instances and Auto Scaling groups runs within your {aws} account. Each node group runs across multiple Availability Zones that you define.

You can add a managed node group to new or existing clusters using the Amazon EKS console, `eksctl`, {aws} CLI; {aws} API, or infrastructure as code tools including {aws} CloudFormation. Nodes launched as part of a managed node group are automatically tagged for auto-discovery by the [.noloc]`Kubernetes` https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md[Cluster Autoscaler]. You can use the node group to apply [.noloc]`Kubernetes` labels to nodes and update them at any time.

There are no additional costs to use Amazon EKS managed node groups, you only pay for the {aws} resources you provision. These include Amazon EC2 instances, Amazon EBS volumes, Amazon EKS cluster hours, and any other {aws} infrastructure. There are no minimum fees and no upfront commitments.

To get started with a new Amazon EKS cluster and managed node group, see <<getting-started-console>>.

To add a managed node group to an existing cluster, see <<create-managed-node-group>>.

[[managed-node-group-concepts,managed-node-group-concepts.title]]
== Managed node groups concepts

* Amazon EKS managed node groups create and manage Amazon EC2 instances for you.
* Every managed node is provisioned as part of an Amazon EC2 Auto Scaling group that's managed for you by Amazon EKS. Moreover, every resource including Amazon EC2 instances and Auto Scaling groups run within your {aws} account.
* The Auto Scaling group of a managed node group spans every subnet that you specify when you create the group.
* Amazon EKS tags managed node group resources so that they are configured to use the [.noloc]`Kubernetes` https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md[Cluster Autoscaler].
+
IMPORTANT: If you are running a stateful application across multiple Availability Zones that is backed by Amazon EBS volumes and using the [.noloc]`Kubernetes` https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md[Cluster Autoscaler], you should configure multiple node groups, each scoped to a single Availability Zone. In addition, you should enable the `--balance-similar-node-groups` feature.
* You can use a custom launch template for a greater level of flexibility and customization when deploying managed nodes. For example, you can specify extra `kubelet` arguments and use a custom AMI. For more information, see <<launch-templates>>. If you don't use a custom launch template when first creating a managed node group, there is an auto-generated launch template. Don't manually modify this auto-generated template or errors occur.
* Amazon EKS follows the shared responsibility model for CVEs and security patches on managed node groups. When managed nodes run an Amazon EKS optimized AMI, Amazon EKS is responsible for building patched versions of the AMI when bugs or issues are reported. We can publish a fix. However, you're responsible for deploying these patched AMI versions to your managed node groups. When managed nodes run a custom AMI, you're responsible for building patched versions of the AMI when bugs or issues are reported and then deploying the AMI. For more information, see <<update-managed-node-group>>. 
* Amazon EKS managed node groups can be launched in both public and private subnets. If you launch a managed node group in a public subnet on or after April 22, 2020, the subnet must have `MapPublicIpOnLaunch` set to true for the instances to successfully join a cluster. If the public subnet was created using `eksctl` or the <<creating-a-vpc,Amazon EKS vended {aws} CloudFormation templates>> on or after March 26, 2020, then this setting is already set to true. If the public subnets were created before March 26, 2020, you must change the setting manually. For more information, see  link:vpc/latest/userguide/vpc-ip-addressing.html#subnet-public-ip[Modifying the public IPv4 addressing attribute for your subnet,type="documentation"].
* When deploying a managed node group in private subnets, you must ensure that it can access Amazon ECR for pulling container images. You can do this by connecting a NAT gateway to the route table of the subnet or by adding the following  link:AmazonECR/latest/userguide/vpc-endpoints.html#ecr-setting-up-vpc-create[{aws} PrivateLink VPC endpoints,type="documentation"]:
+
** Amazon ECR API endpoint interface – `com.amazonaws.[.replaceable]``region-code``.ecr.api`
** Amazon ECR Docker registry API endpoint interface – `com.amazonaws.[.replaceable]``region-code``.ecr.dkr`
** Amazon S3 gateway endpoint – `com.amazonaws.[.replaceable]``region-code``.s3`

+
For other commonly-used services and endpoints, see <<private-clusters>>.
* Managed node groups can't be deployed on <<eks-outposts,{aws} Outposts>> or in {aws} Wavelength or {aws} Local Zones.
* You can create multiple managed node groups within a single cluster. For example, you can create one node group with the standard Amazon EKS optimized Amazon Linux AMI for some workloads and another with the GPU variant for workloads that require GPU support.
* If your managed node group encounters an link:AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html[Amazon EC2 instance status check,type="documentation"] failure, Amazon EKS returns an error code to help you to diagnose the issue. For more information, see <<troubleshoot-managed-node-groups>>.
* Amazon EKS adds [.noloc]`Kubernetes` labels to managed node group instances. These Amazon EKS provided labels are prefixed with `eks.amazonaws.com`.
* Amazon EKS automatically drains nodes using the [.noloc]`Kubernetes` API during terminations or updates.
* Pod disruption budgets aren't respected when terminating a node with `AZRebalance` or reducing the desired node count. These actions try to evict [.noloc]`Pods` on the node. But if it takes more than 15 minutes, the node is terminated regardless of whether all [.noloc]`Pods` on the node are terminated. To extend the period until the node is terminated, add a lifecycle hook to the Auto Scaling group. For more information, see link:autoscaling/ec2/userguide/adding-lifecycle-hooks.html[Add lifecycle hooks,type="documentation"] in the _Amazon EC2 Auto Scaling User Guide_.
* In order to run the drain process correctly after receiving a Spot interruption notification or a capacity rebalance notification, `CapacityRebalance` must be set to `true`.
* Updating managed node groups respects the [.noloc]`Pod` disruption budgets that you set for your [.noloc]`Pods`. For more information, see <<managed-node-update-behavior>>.
* There are no additional costs to use Amazon EKS managed node groups. You only pay for the {aws} resources that you provision.
* If you want to encrypt Amazon EBS volumes for your nodes, you can deploy the nodes using a launch template. To deploy managed nodes with encrypted Amazon EBS volumes without using a launch template, encrypt all new Amazon EBS volumes created in your account. For more information, see  link:AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default[Encryption by default,type="documentation"] in the _Amazon EC2 User Guide_.


[[managed-node-group-capacity-types,managed-node-group-capacity-types.title]]
== Managed node group capacity types

When creating a managed node group, you can choose either the On-Demand or Spot capacity type. Amazon EKS deploys a managed node group with an Amazon EC2 Auto Scaling group that either contains only On-Demand or only Amazon EC2 Spot Instances. You can schedule [.noloc]`Pods` for fault tolerant applications to Spot managed node groups, and fault intolerant applications to On-Demand node groups within a single [.noloc]`Kubernetes` cluster. By default, a managed node group deploys On-Demand Amazon EC2 instances.

[[managed-node-group-capacity-types-on-demand,managed-node-group-capacity-types-on-demand.title]]
=== On-Demand

With On-Demand Instances, you pay for compute capacity by the second, with no long-term commitments.  




By default, if you don't specify a *Capacity Type*, the managed node group is provisioned with On-Demand Instances. A managed node group configures an Amazon EC2 Auto Scaling group on your behalf with the following settings applied:

* The allocation strategy to provision On-Demand capacity is set to `prioritized`. Managed node groups use the order of instance types passed in the API to determine which instance type to use first when fulfilling On-Demand capacity. For example, you might specify three instance types in the following order: `c5.large`, `c4.large`, and `c3.large`. When your On-Demand Instances are launched, the managed node group fulfills On-Demand capacity by starting with `c5.large`, then `c4.large`, and then `c3.large`. For more information, see  link:autoscaling/ec2/userguide/asg-purchase-options.html#asg-allocation-strategies[Amazon EC2 Auto Scaling group,type="documentation"] in the _Amazon EC2 Auto Scaling User Guide_.
* Amazon EKS adds the following [.noloc]`Kubernetes` label to all nodes in your managed node group that specifies the capacity type: `eks.amazonaws.com/capacityType: ON_DEMAND`. You can use this label to schedule stateful or fault intolerant applications on On-Demand nodes. 


[[managed-node-group-capacity-types-spot,managed-node-group-capacity-types-spot.title]]
=== Spot

Amazon EC2 Spot Instances are spare Amazon EC2 capacity that offers steep discounts off of On-Demand prices. Amazon EC2 Spot Instances can be interrupted with a two-minute interruption notice when EC2 needs the capacity back. For more information, see link:AWSEC2/latest/UserGuide/using-spot-instances.html[Spot Instances,type="documentation"] in the _Amazon EC2 User Guide_. You can configure a managed node group with Amazon EC2 Spot Instances to optimize costs for the compute nodes running in your Amazon EKS cluster.




To use Spot Instances inside a managed node group, create a managed node group by setting the capacity type as `spot`. A managed node group configures an Amazon EC2 Auto Scaling group on your behalf with the following Spot best practices applied:

* To ensure that your Spot nodes are provisioned in the optimal Spot capacity pools, the allocation strategy is set to one of the following:
+
** `price-capacity-optimized` (PCO) – When creating new node groups in a cluster with [.noloc]`Kubernetes` version `1.28` or higher, the allocation strategy is set to `price-capacity-optimized`. However, the allocation strategy won't be changed for node groups already created with `capacity-optimized` before Amazon EKS managed node groups started to support PCO.
** `capacity-optimized` (CO) – When creating new node groups in a cluster with [.noloc]`Kubernetes` version `1.27` or lower, the allocation strategy is set to `capacity-optimized`.

+
To increase the number of Spot capacity pools available for allocating capacity from, configure a managed node group to use multiple instance types.
* Amazon EC2 Spot Capacity Rebalancing is enabled so that Amazon EKS can gracefully drain and rebalance your Spot nodes to minimize application disruption when a Spot node is at elevated risk of interruption. For more information, see link:autoscaling/ec2/userguide/capacity-rebalance.html[Amazon EC2 Auto Scaling Capacity Rebalancing,type="documentation"] in the _Amazon EC2 Auto Scaling User Guide_.
+
** When a Spot node receives a rebalance recommendation, Amazon EKS automatically attempts to launch a new replacement Spot node.
** If a Spot two-minute interruption notice arrives before the replacement Spot node is in a `Ready` state, Amazon EKS starts draining the Spot node that received the rebalance recommendation. Amazon EKS drains the node on a best-effort basis. As a result, there's no guarantee that Amazon EKS will wait for the replacement node to join the cluster before draining the existing node.
** When a replacement Spot node is bootstrapped and in the `Ready` state on [.noloc]`Kubernetes`, Amazon EKS cordons and drains the Spot node that received the rebalance recommendation. Cordoning the Spot node ensures that the service controller doesn't send any new requests to this Spot node. It also removes it from its list of healthy, active Spot nodes. Draining the Spot node ensures that running [.noloc]`Pods` are evicted gracefully.
* Amazon EKS adds the following [.noloc]`Kubernetes` label to all nodes in your managed node group that specifies the capacity type: `eks.amazonaws.com/capacityType: SPOT`. You can use this label to schedule fault tolerant applications on Spot nodes.



When deciding whether to deploy a node group with On-Demand or Spot capacity, you should consider the following conditions:

* Spot Instances are a good fit for stateless, fault-tolerant, flexible applications. These include batch and machine learning training workloads, big data ETLs such as Apache Spark, queue processing applications, and stateless API endpoints. Because Spot is spare Amazon EC2 capacity, which can change over time, we recommend that you use Spot capacity for interruption-tolerant workloads. More specifically, Spot capacity is suitable for workloads that can tolerate periods where the required capacity isn't available. 
* We recommend that you use On-Demand for applications that are fault intolerant. This includes cluster management tools such as monitoring and operational tools, deployments that require `StatefulSets`, and stateful applications, such as databases.
* To maximize the availability of your applications while using Spot Instances, we recommend that you configure a Spot managed node group to use multiple instance types. We recommend applying the following rules when using multiple instance types:
+
** Within a managed node group, if you're using the https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/README.md[Cluster Autoscaler], we recommend using a flexible set of instance types with the same amount of vCPU and memory resources. This is to ensure that the nodes in your cluster scale as expected. For example, if you need four vCPUs and eight GiB memory, use `c3.xlarge`, `c4.xlarge`, `c5.xlarge`, `c5d.xlarge`, `c5a.xlarge`, `c5n.xlarge`, or other similar instance types.
** To enhance application availability, we recommend deploying multiple Spot managed node groups. For this, each group should use a flexible set of instance types that have the same vCPU and memory resources. For example, if you need 4 vCPUs and 8 GiB memory, we recommend that you create one managed node group with `c3.xlarge`, `c4.xlarge`, `c5.xlarge`, `c5d.xlarge`, `c5a.xlarge`, `c5n.xlarge`, or other similar instance types, and a second managed node group with `m3.xlarge`, `m4.xlarge`, `m5.xlarge`, `m5d.xlarge`, `m5a.xlarge`, `m5n.xlarge` or other similar instance types.
** When deploying your node group with the Spot capacity type that's using a custom launch template, use the API to pass multiple instance types. Don't pass a single instance type through the launch template. For more information about deploying a node group using a launch template, see <<launch-templates>>.
